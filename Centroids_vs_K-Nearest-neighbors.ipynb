{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-Nearest Neighbors and Centroid Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import operator\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from collections import Counter\n",
    "from matplotlib import pyplot as plt\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import words\n",
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import math\n",
    "import time\n",
    "import sys\n",
    "from scipy import sparse\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Useful functions (normalization, score ...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_mails_ca_is_recipient(training_info, ca):\n",
    "    return training_info[training_info.recipients.map(lambda mail_list: ca in mail_list.split(' '))].mid.tolist()\n",
    "\n",
    "def get_idx_mails_ca_is_recipient(training_info, ca):\n",
    "    return training_info.recipient_list.map(lambda mail_list: ca in mail_list)\n",
    "\n",
    "def normalize(text, tokenize=True, stemmer=False):\n",
    "    porter = nltk.PorterStemmer()\n",
    "    tokenized_text = nltk.word_tokenize(text) if tokenize else text\n",
    "    if stemmer:\n",
    "        normalized_text = [porter.stem(w.lower()) for w in tokenized_text]\n",
    "    else:\n",
    "        normalized_text = [w.lower() for w in tokenized_text]\n",
    "    return normalized_text\n",
    "\n",
    "def filter_vocab(normalized_text, normalized_vocab):\n",
    "    return [w for w in normalized_text if w in normalized_vocab]\n",
    "\n",
    "def is_email_valid(email):\n",
    "    return True if re.match(r\"(^[a-zA-Z0-9_.+-]+@[a-zA-Z0-9-]+\\.[a-zA-Z0-9-.]+$)\", email) else False\n",
    "\n",
    "def get_normalized_body(body_set, filter_english=False, stemmer=False):\n",
    "    if filter_english:\n",
    "        vocab_english_normalized = set(normalize(words.words('en'), tokenize=False, stemmer=stemmer))\n",
    "        return body_set.map(lambda x: filter_vocab(normalize(x, stemmer=stemmer), vocab_english_normalized))\n",
    "    return body_set.map(lambda x: normalize(x, stemmer=stemmer))\n",
    "\n",
    "def get_train_test(df, train_size=0.8):\n",
    "    set_size = df.shape[0]\n",
    "    permutation = np.random.permutation(set_size)\n",
    "    train_idx = permutation[:int(set_size*train_size)]\n",
    "    test_idx = permutation[int(set_size*train_size):]\n",
    "    return df.loc[train_idx], df.loc[test_idx]\n",
    "\n",
    "def fix_mail_list(recipients):\n",
    "    recipients = recipients.split(' ')\n",
    "    return [email for email in recipients if is_email_valid(email)]\n",
    "\n",
    "def get_score(tfidf_mail, centroid_ca):\n",
    "    return np.dot(np.array(centroid_ca)[0], np.array(tfidf_mail)[0])/\\\n",
    "                (np.linalg.norm(tfidf_mail)*np.linalg.norm(centroid_ca))\n",
    "\n",
    "def get_n_best_recipient(tfidf_q, centroid_map, candidates, n=10):\n",
    "    out = {}\n",
    "    for ca in candidates:\n",
    "        score = get_score(tfidf_q, centroid_map[ca].todense())\n",
    "        if not np.isnan(score):\n",
    "            out[ca] = score\n",
    "    out_sorted = sorted(out.items(), key=lambda x: x[1], reverse = True)\n",
    "    return [d[0] for d in out_sorted[:10]]\n",
    "    \n",
    "def apk(actual, predicted, k=10):\n",
    "    if len(predicted)>k:\n",
    "        predicted = predicted[:k]\n",
    "\n",
    "    score = 0.0\n",
    "    num_hits = 0.0\n",
    "\n",
    "    for i,p in enumerate(predicted):\n",
    "        if p in actual and p not in predicted[:i]:\n",
    "            num_hits += 1.0\n",
    "            score += num_hits / (i+1.0)\n",
    "\n",
    "    if not actual:\n",
    "        return 0.0\n",
    "\n",
    "    return score / min(len(actual), k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path_to_data = './'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##########################\n",
    "# load some of the files #                           \n",
    "##########################\n",
    "\n",
    "training = pd.read_csv(path_to_data + 'training_set.csv', sep=',', header=0)\n",
    "training_info = pd.read_csv(path_to_data + 'training_info.csv', sep=',', header=0)\n",
    "test = pd.read_csv(path_to_data + 'test_set.csv', sep=',', header=0)\n",
    "test_info = pd.read_csv(path_to_data + 'test_info.csv', sep=',', header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sender</th>\n",
       "      <th>mids</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>karen.buckley@enron.com</td>\n",
       "      <td>158713 158697 200301 158679 278595 298162 2002...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>amr.ibrahim@enron.com</td>\n",
       "      <td>215241 3437 215640 3506 191790 3517 3520 3562 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>andrea.ring@enron.com</td>\n",
       "      <td>270705 270706 270707 270708 270709 270710 2707...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sylvia.hu@enron.com</td>\n",
       "      <td>111444 111422 183084 111412 111347 110883 1105...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>phillip.platter@enron.com</td>\n",
       "      <td>327074 327384 327385 264443 274124 274125 2741...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      sender  \\\n",
       "0    karen.buckley@enron.com   \n",
       "1      amr.ibrahim@enron.com   \n",
       "2      andrea.ring@enron.com   \n",
       "3        sylvia.hu@enron.com   \n",
       "4  phillip.platter@enron.com   \n",
       "\n",
       "                                                mids  \n",
       "0  158713 158697 200301 158679 278595 298162 2002...  \n",
       "1  215241 3437 215640 3506 191790 3517 3520 3562 ...  \n",
       "2  270705 270706 270707 270708 270709 270710 2707...  \n",
       "3  111444 111422 183084 111412 111347 110883 1105...  \n",
       "4  327074 327384 327385 264443 274124 274125 2741...  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mid</th>\n",
       "      <th>date</th>\n",
       "      <th>body</th>\n",
       "      <th>recipients</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>60</td>\n",
       "      <td>2000-07-25 08:14:00</td>\n",
       "      <td>Legal has been assessing the risks of doing bl...</td>\n",
       "      <td>robert.badeer@enron.com murray.o neil@enron.co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>66</td>\n",
       "      <td>2000-08-03 02:56:00</td>\n",
       "      <td>Attached is a spreadsheet to estimate export f...</td>\n",
       "      <td>kim.ward@enron.com robert.badeer@enron.com mur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>74</td>\n",
       "      <td>2000-08-15 05:37:00</td>\n",
       "      <td>Kevin/Bob: Here is a quick rundown on the cons...</td>\n",
       "      <td>robert.badeer@enron.com john.massey@enron.com ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>80</td>\n",
       "      <td>2000-08-20 14:12:00</td>\n",
       "      <td>check this out and let everyone know what s up...</td>\n",
       "      <td>robert.badeer@enron.com jeff.richter@enron.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>83</td>\n",
       "      <td>2000-08-22 08:17:00</td>\n",
       "      <td>Further to your letter to us (addressed to Mr....</td>\n",
       "      <td>pgillman@schiffhardin.com kamarlantes@calpx.co...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mid                 date  \\\n",
       "0   60  2000-07-25 08:14:00   \n",
       "1   66  2000-08-03 02:56:00   \n",
       "2   74  2000-08-15 05:37:00   \n",
       "3   80  2000-08-20 14:12:00   \n",
       "4   83  2000-08-22 08:17:00   \n",
       "\n",
       "                                                body  \\\n",
       "0  Legal has been assessing the risks of doing bl...   \n",
       "1  Attached is a spreadsheet to estimate export f...   \n",
       "2  Kevin/Bob: Here is a quick rundown on the cons...   \n",
       "3  check this out and let everyone know what s up...   \n",
       "4  Further to your letter to us (addressed to Mr....   \n",
       "\n",
       "                                          recipients  \n",
       "0  robert.badeer@enron.com murray.o neil@enron.co...  \n",
       "1  kim.ward@enron.com robert.badeer@enron.com mur...  \n",
       "2  robert.badeer@enron.com john.massey@enron.com ...  \n",
       "3     robert.badeer@enron.com jeff.richter@enron.com  \n",
       "4  pgillman@schiffhardin.com kamarlantes@calpx.co...  "
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_info.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sender</th>\n",
       "      <th>mids</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>karen.buckley@enron.com</td>\n",
       "      <td>298389 332383 298390 284071 366982 81773 81791...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>amr.ibrahim@enron.com</td>\n",
       "      <td>48260 48465 50344 48268 50330 48237 189979 189...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>andrea.ring@enron.com</td>\n",
       "      <td>366364 271168 271172 271167 271189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sylvia.hu@enron.com</td>\n",
       "      <td>134931 134856 233549 233517 134895 233584 3736...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>phillip.platter@enron.com</td>\n",
       "      <td>274220 274225 274215 274223 274214 274207 2742...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      sender  \\\n",
       "0    karen.buckley@enron.com   \n",
       "1      amr.ibrahim@enron.com   \n",
       "2      andrea.ring@enron.com   \n",
       "3        sylvia.hu@enron.com   \n",
       "4  phillip.platter@enron.com   \n",
       "\n",
       "                                                mids  \n",
       "0  298389 332383 298390 284071 366982 81773 81791...  \n",
       "1  48260 48465 50344 48268 50330 48237 189979 189...  \n",
       "2                 366364 271168 271172 271167 271189  \n",
       "3  134931 134856 233549 233517 134895 233584 3736...  \n",
       "4  274220 274225 274215 274223 274214 274207 2742...  "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mid</th>\n",
       "      <th>date</th>\n",
       "      <th>body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1577</td>\n",
       "      <td>2001-11-19 06:59:51</td>\n",
       "      <td>Note:  Stocks of heating oil are very high for...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1750</td>\n",
       "      <td>2002-03-05 08:46:57</td>\n",
       "      <td>Kevin Hyatt and I are going for \"sghetti\" at S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1916</td>\n",
       "      <td>2002-02-13 14:17:39</td>\n",
       "      <td>This was forwarded to me and it is funny. - Wi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2094</td>\n",
       "      <td>2002-01-22 11:33:56</td>\n",
       "      <td>I will be in to and happy to assist too.  I ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2205</td>\n",
       "      <td>2002-01-11 07:12:19</td>\n",
       "      <td>Thanks. I needed a morning chuckle.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mid                 date  \\\n",
       "0  1577  2001-11-19 06:59:51   \n",
       "1  1750  2002-03-05 08:46:57   \n",
       "2  1916  2002-02-13 14:17:39   \n",
       "3  2094  2002-01-22 11:33:56   \n",
       "4  2205  2002-01-11 07:12:19   \n",
       "\n",
       "                                                body  \n",
       "0  Note:  Stocks of heating oil are very high for...  \n",
       "1  Kevin Hyatt and I are going for \"sghetti\" at S...  \n",
       "2  This was forwarded to me and it is funny. - Wi...  \n",
       "3  I will be in to and happy to assist too.  I ma...  \n",
       "4                Thanks. I needed a morning chuckle.  "
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_info.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(43613, 4)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_info.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2362, 3)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_info.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploration and Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n",
      "110\n",
      "120\n"
     ]
    }
   ],
   "source": [
    "################################\n",
    "# create some handy structures #                    \n",
    "################################\n",
    "                            \n",
    "# convert training set to dictionary\n",
    "emails_ids_per_sender = {}\n",
    "for index, series in training.iterrows():\n",
    "    row = series.tolist()\n",
    "    sender = row[0]\n",
    "    ids = row[1:][0].split(' ')\n",
    "    emails_ids_per_sender[sender] = ids\n",
    "\n",
    "# convert training set to dictionary\n",
    "emails_ids_per_sender_test = {}\n",
    "for index, series in test.iterrows():\n",
    "    row = series.tolist()\n",
    "    sender = row[0]\n",
    "    ids = row[1:][0].split(' ')\n",
    "    emails_ids_per_sender_test[sender] = ids\n",
    "    \n",
    "# save all unique sender names\n",
    "all_senders = emails_ids_per_sender.keys()\n",
    "\n",
    "# create address book with frequency information for each user\n",
    "address_books = {}\n",
    "i = 0\n",
    "\n",
    "for sender, ids in emails_ids_per_sender.items():\n",
    "    recs_temp = []\n",
    "    for my_id in ids:\n",
    "        recipients = training_info[training_info['mid']==int(my_id)]['recipients'].tolist()\n",
    "        recipients = recipients[0].split(' ')\n",
    "        # keep only legitimate email addresses\n",
    "        recipients = [rec for rec in recipients if '@' in rec]\n",
    "        recs_temp.append(recipients)\n",
    "    # flatten    \n",
    "    recs_temp = [elt for sublist in recs_temp for elt in sublist]\n",
    "    # compute recipient counts\n",
    "    rec_occ = dict(Counter(recs_temp))\n",
    "    # order by frequency\n",
    "    sorted_rec_occ = sorted(rec_occ.items(), key=operator.itemgetter(1), reverse = True)\n",
    "    # save\n",
    "    address_books[sender] = sorted_rec_occ\n",
    "    \n",
    "    if i % 10 == 0:\n",
    "        print(i)\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sender_per_mid = {}\n",
    "for key in emails_ids_per_sender_test.keys():\n",
    "    mids = emails_ids_per_sender_test[key]\n",
    "    for mid in mids:\n",
    "        sender_per_mid[mid] = key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#sender_per_mid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#emails_ids_per_sender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "training_info['normalized_body'] = get_normalized_body(training_info.body, stemmer=True)\n",
    "test_info['normalized_body'] = get_normalized_body(test_info.body, stemmer=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mid</th>\n",
       "      <th>date</th>\n",
       "      <th>body</th>\n",
       "      <th>recipients</th>\n",
       "      <th>normalized_body</th>\n",
       "      <th>body_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>60</td>\n",
       "      <td>2000-07-25 08:14:00</td>\n",
       "      <td>Legal has been assessing the risks of doing bl...</td>\n",
       "      <td>robert.badeer@enron.com murray.o neil@enron.co...</td>\n",
       "      <td>[legal, ha, been, assess, the, risk, of, do, b...</td>\n",
       "      <td>legal ha been assess the risk of do block forw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>66</td>\n",
       "      <td>2000-08-03 02:56:00</td>\n",
       "      <td>Attached is a spreadsheet to estimate export f...</td>\n",
       "      <td>kim.ward@enron.com robert.badeer@enron.com mur...</td>\n",
       "      <td>[attach, is, a, spreadsheet, to, estim, export...</td>\n",
       "      <td>attach is a spreadsheet to estim export fee .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>74</td>\n",
       "      <td>2000-08-15 05:37:00</td>\n",
       "      <td>Kevin/Bob: Here is a quick rundown on the cons...</td>\n",
       "      <td>robert.badeer@enron.com john.massey@enron.com ...</td>\n",
       "      <td>[kevin/bob, :, here, is, a, quick, rundown, on...</td>\n",
       "      <td>kevin/bob : here is a quick rundown on the con...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>80</td>\n",
       "      <td>2000-08-20 14:12:00</td>\n",
       "      <td>check this out and let everyone know what s up...</td>\n",
       "      <td>robert.badeer@enron.com jeff.richter@enron.com</td>\n",
       "      <td>[check, thi, out, and, let, everyon, know, wha...</td>\n",
       "      <td>check thi out and let everyon know what s up. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>83</td>\n",
       "      <td>2000-08-22 08:17:00</td>\n",
       "      <td>Further to your letter to us (addressed to Mr....</td>\n",
       "      <td>pgillman@schiffhardin.com kamarlantes@calpx.co...</td>\n",
       "      <td>[further, to, your, letter, to, us, (, address...</td>\n",
       "      <td>further to your letter to us ( address to mr. ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mid                 date  \\\n",
       "0   60  2000-07-25 08:14:00   \n",
       "1   66  2000-08-03 02:56:00   \n",
       "2   74  2000-08-15 05:37:00   \n",
       "3   80  2000-08-20 14:12:00   \n",
       "4   83  2000-08-22 08:17:00   \n",
       "\n",
       "                                                body  \\\n",
       "0  Legal has been assessing the risks of doing bl...   \n",
       "1  Attached is a spreadsheet to estimate export f...   \n",
       "2  Kevin/Bob: Here is a quick rundown on the cons...   \n",
       "3  check this out and let everyone know what s up...   \n",
       "4  Further to your letter to us (addressed to Mr....   \n",
       "\n",
       "                                          recipients  \\\n",
       "0  robert.badeer@enron.com murray.o neil@enron.co...   \n",
       "1  kim.ward@enron.com robert.badeer@enron.com mur...   \n",
       "2  robert.badeer@enron.com john.massey@enron.com ...   \n",
       "3     robert.badeer@enron.com jeff.richter@enron.com   \n",
       "4  pgillman@schiffhardin.com kamarlantes@calpx.co...   \n",
       "\n",
       "                                     normalized_body  \\\n",
       "0  [legal, ha, been, assess, the, risk, of, do, b...   \n",
       "1  [attach, is, a, spreadsheet, to, estim, export...   \n",
       "2  [kevin/bob, :, here, is, a, quick, rundown, on...   \n",
       "3  [check, thi, out, and, let, everyon, know, wha...   \n",
       "4  [further, to, your, letter, to, us, (, address...   \n",
       "\n",
       "                                           body_text  \n",
       "0  legal ha been assess the risk of do block forw...  \n",
       "1      attach is a spreadsheet to estim export fee .  \n",
       "2  kevin/bob : here is a quick rundown on the con...  \n",
       "3  check thi out and let everyon know what s up. ...  \n",
       "4  further to your letter to us ( address to mr. ...  "
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_info.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mid</th>\n",
       "      <th>date</th>\n",
       "      <th>body</th>\n",
       "      <th>normalized_body</th>\n",
       "      <th>body_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1577</td>\n",
       "      <td>2001-11-19 06:59:51</td>\n",
       "      <td>Note:  Stocks of heating oil are very high for...</td>\n",
       "      <td>[note, :, stock, of, heat, oil, are, veri, hig...</td>\n",
       "      <td>note : stock of heat oil are veri high for thi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1750</td>\n",
       "      <td>2002-03-05 08:46:57</td>\n",
       "      <td>Kevin Hyatt and I are going for \"sghetti\" at S...</td>\n",
       "      <td>[kevin, hyatt, and, i, are, go, for, ``, sghet...</td>\n",
       "      <td>kevin hyatt and i are go for `` sghetti '' at ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1916</td>\n",
       "      <td>2002-02-13 14:17:39</td>\n",
       "      <td>This was forwarded to me and it is funny. - Wi...</td>\n",
       "      <td>[thi, wa, forward, to, me, and, it, is, funni,...</td>\n",
       "      <td>thi wa forward to me and it is funni . - witci...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2094</td>\n",
       "      <td>2002-01-22 11:33:56</td>\n",
       "      <td>I will be in to and happy to assist too.  I ma...</td>\n",
       "      <td>[i, will, be, in, to, and, happi, to, assist, ...</td>\n",
       "      <td>i will be in to and happi to assist too . i ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2205</td>\n",
       "      <td>2002-01-11 07:12:19</td>\n",
       "      <td>Thanks. I needed a morning chuckle.</td>\n",
       "      <td>[thank, ., i, need, a, morn, chuckl, .]</td>\n",
       "      <td>thank . i need a morn chuckl .</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mid                 date  \\\n",
       "0  1577  2001-11-19 06:59:51   \n",
       "1  1750  2002-03-05 08:46:57   \n",
       "2  1916  2002-02-13 14:17:39   \n",
       "3  2094  2002-01-22 11:33:56   \n",
       "4  2205  2002-01-11 07:12:19   \n",
       "\n",
       "                                                body  \\\n",
       "0  Note:  Stocks of heating oil are very high for...   \n",
       "1  Kevin Hyatt and I are going for \"sghetti\" at S...   \n",
       "2  This was forwarded to me and it is funny. - Wi...   \n",
       "3  I will be in to and happy to assist too.  I ma...   \n",
       "4                Thanks. I needed a morning chuckle.   \n",
       "\n",
       "                                     normalized_body  \\\n",
       "0  [note, :, stock, of, heat, oil, are, veri, hig...   \n",
       "1  [kevin, hyatt, and, i, are, go, for, ``, sghet...   \n",
       "2  [thi, wa, forward, to, me, and, it, is, funni,...   \n",
       "3  [i, will, be, in, to, and, happi, to, assist, ...   \n",
       "4            [thank, ., i, need, a, morn, chuckl, .]   \n",
       "\n",
       "                                           body_text  \n",
       "0  note : stock of heat oil are veri high for thi...  \n",
       "1  kevin hyatt and i are go for `` sghetti '' at ...  \n",
       "2  thi wa forward to me and it is funni . - witci...  \n",
       "3  i will be in to and happi to assist too . i ma...  \n",
       "4                     thank . i need a morn chuckl .  "
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_info.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training_info['body_text'] = training_info.normalized_body.map(lambda x: ' '.join(x))\n",
    "test_info['body_text'] = test_info.normalized_body.map(lambda x: ' '.join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mid</th>\n",
       "      <th>date</th>\n",
       "      <th>body</th>\n",
       "      <th>recipients</th>\n",
       "      <th>normalized_body</th>\n",
       "      <th>body_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>60</td>\n",
       "      <td>2000-07-25 08:14:00</td>\n",
       "      <td>Legal has been assessing the risks of doing bl...</td>\n",
       "      <td>robert.badeer@enron.com murray.o neil@enron.co...</td>\n",
       "      <td>[legal, ha, been, assess, the, risk, of, do, b...</td>\n",
       "      <td>legal ha been assess the risk of do block forw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>66</td>\n",
       "      <td>2000-08-03 02:56:00</td>\n",
       "      <td>Attached is a spreadsheet to estimate export f...</td>\n",
       "      <td>kim.ward@enron.com robert.badeer@enron.com mur...</td>\n",
       "      <td>[attach, is, a, spreadsheet, to, estim, export...</td>\n",
       "      <td>attach is a spreadsheet to estim export fee .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>74</td>\n",
       "      <td>2000-08-15 05:37:00</td>\n",
       "      <td>Kevin/Bob: Here is a quick rundown on the cons...</td>\n",
       "      <td>robert.badeer@enron.com john.massey@enron.com ...</td>\n",
       "      <td>[kevin/bob, :, here, is, a, quick, rundown, on...</td>\n",
       "      <td>kevin/bob : here is a quick rundown on the con...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>80</td>\n",
       "      <td>2000-08-20 14:12:00</td>\n",
       "      <td>check this out and let everyone know what s up...</td>\n",
       "      <td>robert.badeer@enron.com jeff.richter@enron.com</td>\n",
       "      <td>[check, thi, out, and, let, everyon, know, wha...</td>\n",
       "      <td>check thi out and let everyon know what s up. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>83</td>\n",
       "      <td>2000-08-22 08:17:00</td>\n",
       "      <td>Further to your letter to us (addressed to Mr....</td>\n",
       "      <td>pgillman@schiffhardin.com kamarlantes@calpx.co...</td>\n",
       "      <td>[further, to, your, letter, to, us, (, address...</td>\n",
       "      <td>further to your letter to us ( address to mr. ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mid                 date  \\\n",
       "0   60  2000-07-25 08:14:00   \n",
       "1   66  2000-08-03 02:56:00   \n",
       "2   74  2000-08-15 05:37:00   \n",
       "3   80  2000-08-20 14:12:00   \n",
       "4   83  2000-08-22 08:17:00   \n",
       "\n",
       "                                                body  \\\n",
       "0  Legal has been assessing the risks of doing bl...   \n",
       "1  Attached is a spreadsheet to estimate export f...   \n",
       "2  Kevin/Bob: Here is a quick rundown on the cons...   \n",
       "3  check this out and let everyone know what s up...   \n",
       "4  Further to your letter to us (addressed to Mr....   \n",
       "\n",
       "                                          recipients  \\\n",
       "0  robert.badeer@enron.com murray.o neil@enron.co...   \n",
       "1  kim.ward@enron.com robert.badeer@enron.com mur...   \n",
       "2  robert.badeer@enron.com john.massey@enron.com ...   \n",
       "3     robert.badeer@enron.com jeff.richter@enron.com   \n",
       "4  pgillman@schiffhardin.com kamarlantes@calpx.co...   \n",
       "\n",
       "                                     normalized_body  \\\n",
       "0  [legal, ha, been, assess, the, risk, of, do, b...   \n",
       "1  [attach, is, a, spreadsheet, to, estim, export...   \n",
       "2  [kevin/bob, :, here, is, a, quick, rundown, on...   \n",
       "3  [check, thi, out, and, let, everyon, know, wha...   \n",
       "4  [further, to, your, letter, to, us, (, address...   \n",
       "\n",
       "                                           body_text  \n",
       "0  legal ha been assess the risk of do block forw...  \n",
       "1      attach is a spreadsheet to estim export fee .  \n",
       "2  kevin/bob : here is a quick rundown on the con...  \n",
       "3  check thi out and let everyon know what s up. ...  \n",
       "4  further to your letter to us ( address to mr. ...  "
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_info.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mid</th>\n",
       "      <th>date</th>\n",
       "      <th>body</th>\n",
       "      <th>normalized_body</th>\n",
       "      <th>body_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1577</td>\n",
       "      <td>2001-11-19 06:59:51</td>\n",
       "      <td>Note:  Stocks of heating oil are very high for...</td>\n",
       "      <td>[note, :, stock, of, heat, oil, are, veri, hig...</td>\n",
       "      <td>note : stock of heat oil are veri high for thi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1750</td>\n",
       "      <td>2002-03-05 08:46:57</td>\n",
       "      <td>Kevin Hyatt and I are going for \"sghetti\" at S...</td>\n",
       "      <td>[kevin, hyatt, and, i, are, go, for, ``, sghet...</td>\n",
       "      <td>kevin hyatt and i are go for `` sghetti '' at ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1916</td>\n",
       "      <td>2002-02-13 14:17:39</td>\n",
       "      <td>This was forwarded to me and it is funny. - Wi...</td>\n",
       "      <td>[thi, wa, forward, to, me, and, it, is, funni,...</td>\n",
       "      <td>thi wa forward to me and it is funni . - witci...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2094</td>\n",
       "      <td>2002-01-22 11:33:56</td>\n",
       "      <td>I will be in to and happy to assist too.  I ma...</td>\n",
       "      <td>[i, will, be, in, to, and, happi, to, assist, ...</td>\n",
       "      <td>i will be in to and happi to assist too . i ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2205</td>\n",
       "      <td>2002-01-11 07:12:19</td>\n",
       "      <td>Thanks. I needed a morning chuckle.</td>\n",
       "      <td>[thank, ., i, need, a, morn, chuckl, .]</td>\n",
       "      <td>thank . i need a morn chuckl .</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mid                 date  \\\n",
       "0  1577  2001-11-19 06:59:51   \n",
       "1  1750  2002-03-05 08:46:57   \n",
       "2  1916  2002-02-13 14:17:39   \n",
       "3  2094  2002-01-22 11:33:56   \n",
       "4  2205  2002-01-11 07:12:19   \n",
       "\n",
       "                                                body  \\\n",
       "0  Note:  Stocks of heating oil are very high for...   \n",
       "1  Kevin Hyatt and I are going for \"sghetti\" at S...   \n",
       "2  This was forwarded to me and it is funny. - Wi...   \n",
       "3  I will be in to and happy to assist too.  I ma...   \n",
       "4                Thanks. I needed a morning chuckle.   \n",
       "\n",
       "                                     normalized_body  \\\n",
       "0  [note, :, stock, of, heat, oil, are, veri, hig...   \n",
       "1  [kevin, hyatt, and, i, are, go, for, ``, sghet...   \n",
       "2  [thi, wa, forward, to, me, and, it, is, funni,...   \n",
       "3  [i, will, be, in, to, and, happi, to, assist, ...   \n",
       "4            [thank, ., i, need, a, morn, chuckl, .]   \n",
       "\n",
       "                                           body_text  \n",
       "0  note : stock of heat oil are veri high for thi...  \n",
       "1  kevin hyatt and i are go for `` sghetti '' at ...  \n",
       "2  thi wa forward to me and it is funni . - witci...  \n",
       "3  i will be in to and happi to assist too . i ma...  \n",
       "4                     thank . i need a morn chuckl .  "
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_info.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "corpus = training_info.body_text\n",
    "vectorizer = TfidfVectorizer(min_df=2, max_df=0.005)\n",
    "tfidf = vectorizer.fit_transform(corpus)\n",
    "tfidf_test = vectorizer.transform(test_info.body_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<43613x83000 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 953074 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "training_info['recipient_list'] = training_info.recipients.map(lambda x: fix_mail_list(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mid</th>\n",
       "      <th>date</th>\n",
       "      <th>body</th>\n",
       "      <th>recipients</th>\n",
       "      <th>normalized_body</th>\n",
       "      <th>body_text</th>\n",
       "      <th>recipient_list</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>60</td>\n",
       "      <td>2000-07-25 08:14:00</td>\n",
       "      <td>Legal has been assessing the risks of doing bl...</td>\n",
       "      <td>robert.badeer@enron.com murray.o neil@enron.co...</td>\n",
       "      <td>[legal, has, been, assessing, the, risks, of, ...</td>\n",
       "      <td>legal has been assessing the risks of doing bl...</td>\n",
       "      <td>[robert.badeer@enron.com, murray.oneil@enron.c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>66</td>\n",
       "      <td>2000-08-03 02:56:00</td>\n",
       "      <td>Attached is a spreadsheet to estimate export f...</td>\n",
       "      <td>kim.ward@enron.com robert.badeer@enron.com mur...</td>\n",
       "      <td>[attached, is, a, spreadsheet, to, estimate, e...</td>\n",
       "      <td>attached is a spreadsheet to estimate export f...</td>\n",
       "      <td>[kim.ward@enron.com, robert.badeer@enron.com, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>74</td>\n",
       "      <td>2000-08-15 05:37:00</td>\n",
       "      <td>Kevin/Bob: Here is a quick rundown on the cons...</td>\n",
       "      <td>robert.badeer@enron.com john.massey@enron.com ...</td>\n",
       "      <td>[kevin/bob, :, here, is, a, quick, rundown, on...</td>\n",
       "      <td>kevin/bob : here is a quick rundown on the con...</td>\n",
       "      <td>[robert.badeer@enron.com, john.massey@enron.co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>80</td>\n",
       "      <td>2000-08-20 14:12:00</td>\n",
       "      <td>check this out and let everyone know what s up...</td>\n",
       "      <td>robert.badeer@enron.com jeff.richter@enron.com</td>\n",
       "      <td>[check, this, out, and, let, everyone, know, w...</td>\n",
       "      <td>check this out and let everyone know what s up...</td>\n",
       "      <td>[robert.badeer@enron.com, jeff.richter@enron.com]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>83</td>\n",
       "      <td>2000-08-22 08:17:00</td>\n",
       "      <td>Further to your letter to us (addressed to Mr....</td>\n",
       "      <td>pgillman@schiffhardin.com kamarlantes@calpx.co...</td>\n",
       "      <td>[further, to, your, letter, to, us, (, address...</td>\n",
       "      <td>further to your letter to us ( addressed to mr...</td>\n",
       "      <td>[pgillman@schiffhardin.com, kamarlantes@calpx....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mid                 date  \\\n",
       "0   60  2000-07-25 08:14:00   \n",
       "1   66  2000-08-03 02:56:00   \n",
       "2   74  2000-08-15 05:37:00   \n",
       "3   80  2000-08-20 14:12:00   \n",
       "4   83  2000-08-22 08:17:00   \n",
       "\n",
       "                                                body  \\\n",
       "0  Legal has been assessing the risks of doing bl...   \n",
       "1  Attached is a spreadsheet to estimate export f...   \n",
       "2  Kevin/Bob: Here is a quick rundown on the cons...   \n",
       "3  check this out and let everyone know what s up...   \n",
       "4  Further to your letter to us (addressed to Mr....   \n",
       "\n",
       "                                          recipients  \\\n",
       "0  robert.badeer@enron.com murray.o neil@enron.co...   \n",
       "1  kim.ward@enron.com robert.badeer@enron.com mur...   \n",
       "2  robert.badeer@enron.com john.massey@enron.com ...   \n",
       "3     robert.badeer@enron.com jeff.richter@enron.com   \n",
       "4  pgillman@schiffhardin.com kamarlantes@calpx.co...   \n",
       "\n",
       "                                     normalized_body  \\\n",
       "0  [legal, has, been, assessing, the, risks, of, ...   \n",
       "1  [attached, is, a, spreadsheet, to, estimate, e...   \n",
       "2  [kevin/bob, :, here, is, a, quick, rundown, on...   \n",
       "3  [check, this, out, and, let, everyone, know, w...   \n",
       "4  [further, to, your, letter, to, us, (, address...   \n",
       "\n",
       "                                           body_text  \\\n",
       "0  legal has been assessing the risks of doing bl...   \n",
       "1  attached is a spreadsheet to estimate export f...   \n",
       "2  kevin/bob : here is a quick rundown on the con...   \n",
       "3  check this out and let everyone know what s up...   \n",
       "4  further to your letter to us ( addressed to mr...   \n",
       "\n",
       "                                      recipient_list  \n",
       "0  [robert.badeer@enron.com, murray.oneil@enron.c...  \n",
       "1  [kim.ward@enron.com, robert.badeer@enron.com, ...  \n",
       "2  [robert.badeer@enron.com, john.massey@enron.co...  \n",
       "3  [robert.badeer@enron.com, jeff.richter@enron.com]  \n",
       "4  [pgillman@schiffhardin.com, kamarlantes@calpx....  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_info.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_recipients = np.unique(np.concatenate(training_info.recipient_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train, test = get_train_test(training_info)\n",
    "all_recipients = np.unique(np.concatenate(train.recipient_list.tolist()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "porter = nltk.PorterStemmer()\n",
    "#vectorizer = TfidfVectorizer(min_df=2, stop_words=[porter.stem(w.lower()) for w in stopwords.words('english')])\n",
    "vectorizer = TfidfVectorizer(min_df=5, stop_words=[w.lower() for w in stopwords.words('english')])\n",
    "tfidf_train_ = vectorizer.fit_transform(train.body_text)\n",
    "tfidf_test_ = vectorizer.transform(test.body_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(34890, 34659)"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_train_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train['recipient_list'] = train.recipients.map(lambda x: fix_mail_list(x))\n",
    "test['recipient_list'] = test.recipients.map(lambda x: fix_mail_list(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#sum_ca = sum(tfidf_train_.todense())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1/ Centroid Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def centroid(ca):\n",
    "    #alpha = 16\n",
    "    #beta = 4\n",
    "    #sent_train = tfidf_train_.shape[0]\n",
    "    D_ca = get_idx_mails_ca_is_recipient(train, ca)\n",
    "    n_D_ca = sum(D_ca)\n",
    "    sum_D_ca = sum(tfidf_train_[np.argwhere(D_ca == True).flatten(),].todense())\n",
    "    #sum_not_D_ca = sum_ca - sum_D_ca\n",
    "    #return (alpha/n_D_ca)*sum_D_ca + (beta/(sent_train-n_D_ca))*sum_not_D_ca\n",
    "    return (1/n_D_ca)*sum_D_ca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100% done"
     ]
    }
   ],
   "source": [
    "centroid_map = {}\n",
    "for index, mail in enumerate(all_recipients):\n",
    "    if index % 20 == 0:\n",
    "        sys.stdout.write(\"\\r\"+str(math.ceil(100*index/len(all_recipients)))+\"% done\")\n",
    "        sys.stdout.flush()\n",
    "    centroid_map[mail] = sparse.coo_matrix(centroid(mail))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n### On test set\\n\\ns = 0\\nrecipient_list_ = test.recipient_list.tolist()\\nfor i in range(test.shape[0]):\\n    score = apk(recipient_list_[i], get_n_best_recipient(tfidf_test_[i].todense(), centroid_map, all_recipients))\\n    s += score\\n    print(i+1, s/(i+1), score)\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "### On test set\n",
    "\n",
    "s = 0\n",
    "recipient_list_ = test.recipient_list.tolist()\n",
    "for i in range(test.shape[0]):\n",
    "    score = apk(recipient_list_[i], get_n_best_recipient(tfidf_test_[i].todense(), centroid_map, all_recipients))\n",
    "    s += score\n",
    "    print(i+1, s/(i+1), score)\n",
    "\"\"\"  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### On train set\n",
    "\n",
    "#s = 0\n",
    "#recipient_list_ = train.recipient_list.tolist()\n",
    "#for i in range(train.shape[0]):\n",
    "#    score = apk(recipient_list_[i], get_n_best_recipient(tfidf_train_[i].todense(), centroid_map, all_recipients))\n",
    "#    s += score\n",
    "#    print(i+1, s/(i+1), score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 2/K-Nearest Neighbors Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_inv_norm_sparse_matrix(sm, fraction=20):\n",
    "    out = []\n",
    "    n_components = sm.shape[0]\n",
    "    block_size = math.floor(n_components/fraction)\n",
    "    for i in range(fraction+1):\n",
    "        sys.stdout.write(\"\\r\"+str(math.ceil(100*i/fraction))+\"% done\")\n",
    "        sys.stdout.flush()\n",
    "        sm_block = sm[i*block_size:min((i+1)*block_size, n_components)]\n",
    "        sm_block_norm = list(sm_block.dot(sm_block.T).dot(sparse.identity(sm_block.shape[0])).dot(np.ones(sm_block.shape[0])))\n",
    "        sm_block_norm = [1/math.sqrt(x) if x != 0 else np.inf for x in sm_block_norm]\n",
    "        out += list(sm_block_norm)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100% done"
     ]
    }
   ],
   "source": [
    "idtdf_inv_norm = np.array(get_inv_norm_sparse_matrix(tfidf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100% done"
     ]
    }
   ],
   "source": [
    "idtdf_test_inv_norm = np.array(get_inv_norm_sparse_matrix(tfidf_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(43613, 2362)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_not_normalized = tfidf.dot(tfidf_test.T)\n",
    "cosine_not_normalized.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(43613, 2362)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inv_norm_product = idtdf_inv_norm.reshape(len(idtdf_inv_norm),1).dot(idtdf_test_inv_norm.reshape(1,len(idtdf_test_inv_norm)))\n",
    "inv_norm_product.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(43613, 2362)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_normalized = np.array(cosine_not_normalized.todense())*inv_norm_product\n",
    "cosine_normalized.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(43613, 2362)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_normalized_sorted_arg = np.array(np.argsort(-cosine_normalized, axis=0))\n",
    "cosine_normalized_sorted_arg.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100% done"
     ]
    }
   ],
   "source": [
    "most_similar_docs = []\n",
    "docs_in_test = cosine_normalized_sorted_arg.shape[1]\n",
    "for idx in range(docs_in_test):\n",
    "    sys.stdout.write(\"\\r\"+str(math.ceil(100*idx/docs_in_test))+\"% done\")\n",
    "    sys.stdout.flush()\n",
    "    most_similar_docs.append([y[1] for y in sorted([(x, index) for (x, index) in enumerate(cosine_normalized_sorted_arg[:,idx])])[:30]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2362, 30)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "most_similar_docs = np.array(most_similar_docs)\n",
    "most_similar_docs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_score(ca, idx_test, most_similar_docs=most_similar_docs, df=training_info, cosine_normalized=cosine_normalized):\n",
    "    return np.sum(np.array([1 if ca in x else 0 for x in df.recipient_list.loc[most_similar_docs[idx_test]].values])*np.array([cosine_normalized[idx_train, idx_test] for idx_train in most_similar_docs[idx_test]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_best_n_recipient(idx_test):\n",
    "    mid = test_info.mid[idx_test]\n",
    "    sender = sender_per_mid[str(mid)]\n",
    "    recipients_potential = [x[0] for x in address_books[sender]]\n",
    "    out = {}\n",
    "    for index, ca in enumerate(all_recipients):\n",
    "        #sys.stdout.write(\"\\r\"+str(math.ceil(100*index/len(all_recipients)))+\"% done\")\n",
    "        #sys.stdout.flush()\n",
    "        out[ca] = get_score(ca, idx_test)\n",
    "    return [y[0] for y in sorted(out.items(), key=lambda x: x[1], reverse=True) if y[0] in recipients_potential][:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n",
      "110\n",
      "120\n",
      "130\n",
      "140\n",
      "150\n",
      "160\n",
      "170\n",
      "180\n",
      "190\n",
      "200\n",
      "210\n",
      "220\n",
      "230\n",
      "240\n",
      "250\n",
      "260\n",
      "270\n",
      "280\n",
      "290\n",
      "300\n",
      "310\n",
      "320\n",
      "330\n",
      "340\n",
      "350\n",
      "360\n",
      "370\n",
      "380\n",
      "390\n",
      "400\n",
      "410\n",
      "420\n",
      "430\n",
      "440\n",
      "450\n",
      "460\n",
      "470\n",
      "480\n",
      "490\n",
      "500\n",
      "510\n",
      "520\n",
      "530\n",
      "540\n",
      "550\n",
      "560\n",
      "570\n",
      "580\n",
      "590\n",
      "600\n",
      "610\n",
      "620\n",
      "630\n",
      "640\n",
      "650\n",
      "660\n",
      "670\n",
      "680\n",
      "690\n",
      "700\n",
      "710\n",
      "720\n",
      "730\n",
      "740\n",
      "750\n",
      "760\n",
      "770\n",
      "780\n",
      "790\n",
      "800\n",
      "810\n",
      "820\n",
      "830\n",
      "840\n",
      "850\n",
      "860\n",
      "870\n",
      "880\n",
      "890\n",
      "900\n",
      "910\n",
      "920\n",
      "930\n",
      "940\n",
      "950\n",
      "960\n",
      "970\n",
      "980\n",
      "990\n",
      "1000\n",
      "1010\n",
      "1020\n",
      "1030\n",
      "1040\n",
      "1050\n",
      "1060\n",
      "1070\n",
      "1080\n",
      "1090\n",
      "1100\n",
      "1110\n",
      "1120\n",
      "1130\n",
      "1140\n",
      "1150\n",
      "1160\n",
      "1170\n",
      "1180\n",
      "1190\n",
      "1200\n",
      "1210\n",
      "1220\n",
      "1230\n",
      "1240\n",
      "1250\n",
      "1260\n",
      "1270\n",
      "1280\n",
      "1290\n",
      "1300\n",
      "1310\n",
      "1320\n",
      "1330\n",
      "1340\n",
      "1350\n",
      "1360\n",
      "1370\n",
      "1380\n",
      "1390\n",
      "1400\n",
      "1410\n",
      "1420\n",
      "1430\n",
      "1440\n",
      "1450\n",
      "1460\n",
      "1470\n",
      "1480\n",
      "1490\n",
      "1500\n",
      "1510\n",
      "1520\n",
      "1530\n",
      "1540\n",
      "1550\n",
      "1560\n",
      "1570\n",
      "1580\n",
      "1590\n",
      "1600\n",
      "1610\n",
      "1620\n",
      "1630\n",
      "1640\n",
      "1650\n",
      "1660\n",
      "1670\n",
      "1680\n",
      "1690\n",
      "1700\n",
      "1710\n",
      "1720\n",
      "1730\n",
      "1740\n",
      "1750\n",
      "1760\n",
      "1770\n",
      "1780\n",
      "1790\n",
      "1800\n",
      "1810\n",
      "1820\n",
      "1830\n",
      "1840\n",
      "1850\n",
      "1860\n",
      "1870\n",
      "1880\n",
      "1890\n",
      "1900\n",
      "1910\n",
      "1920\n",
      "1930\n",
      "1940\n",
      "1950\n",
      "1960\n",
      "1970\n",
      "1980\n",
      "1990\n",
      "2000\n",
      "2010\n",
      "2020\n",
      "2030\n",
      "2040\n",
      "2050\n",
      "2060\n",
      "2070\n",
      "2080\n",
      "2090\n",
      "2100\n",
      "2110\n",
      "2120\n",
      "2130\n",
      "2140\n",
      "2150\n",
      "2160\n",
      "2170\n",
      "2180\n",
      "2190\n",
      "2200\n",
      "2210\n",
      "2220\n",
      "2230\n",
      "2240\n",
      "2250\n",
      "2260\n",
      "2270\n",
      "2280\n",
      "2290\n",
      "2300\n",
      "2310\n",
      "2320\n",
      "2330\n",
      "2340\n",
      "2350\n",
      "2360\n"
     ]
    }
   ],
   "source": [
    "out_final = []\n",
    "path_to_results = './'\n",
    "for i in range(test_info.shape[0]):\n",
    "    out_final.append(get_best_n_recipient(i))\n",
    "    if i % 10 == 0:\n",
    "        print(i)\n",
    "        with open(path_to_results + 'res_knn.txt', 'w') as my_file:\n",
    "            for index, my_preds in enumerate(out_final):\n",
    "                my_file.write(str(index) + ',' + ' '.join(my_preds) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path_to_results = './'\n",
    "with open(path_to_results + 'predictions_knn.txt', 'w') as my_file:\n",
    "    my_file.write('mid,recipients' + '\\n')\n",
    "    for mid, my_preds in zip(test_info.mid, out_final):\n",
    "        my_file.write(str(mid) + ',' + ' '.join(my_preds) + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a result on the public leaderboard, we get a MAP@10 of 0.31 for centroids and 0.27 for K-Nearest neighbors."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
