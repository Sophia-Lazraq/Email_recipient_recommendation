{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import operator\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from collections import Counter\n",
    "from matplotlib import pyplot as plt\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import words\n",
    "from nltk.corpus import names\n",
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import math\n",
    "import time\n",
    "import sys\n",
    "from scipy import sparse\n",
    "import string\n",
    "from normalization import normalize_corpus\n",
    "from utils import build_feature_matrix\n",
    "import scipy.sparse as sp\n",
    "%matplotlib inline\n",
    "import warnings\n",
    "from scipy.sparse import coo_matrix\n",
    "from scipy.sparse import csr_matrix\n",
    "from scipy.sparse import csc_matrix\n",
    "warnings.filterwarnings('ignore')\n",
    "from time import time\n",
    "from __future__ import division\n",
    "from operator import le, lt, ge, gt\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Some useful functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def log_process(cursor, finish_cursor, start_time = None):\n",
    "    percentage = float(cursor + 1)/finish_cursor\n",
    "    now_time = time()\n",
    "    time_to_finish = ((now_time - start_time)/percentage) - (now_time - start_time)\n",
    "    mn, sc = int(time_to_finish//60), int((time_to_finish/60 - time_to_finish//60)*60)\n",
    "    if start_time:\n",
    "        sys.stdout.write(\"\\r%.2f%% ----- Temps restant estimé: %d min %d sec -----\" %(100*percentage, mn, sc))\n",
    "        sys.stdout.flush()\n",
    "    else:\n",
    "        sys.stdout.write(\"\\r%.2f%%\" %(100*percentage))\n",
    "        sys.stdout.flush()\n",
    "\n",
    "def get_true_recipient(mid):\n",
    "    return training_info[training_info.mid == mid].recipients_valid.tolist()[0]\n",
    "        \n",
    "def simplify_date(date):\n",
    "    return re.findall(\"[0-9]{4}-[0-9]{2}-[0-9]{2}\", date)[0]\n",
    "\n",
    "def is_email_valid(email):\n",
    "    return True if re.match(r\"(^[a-zA-Z0-9_.+-]+@[a-zA-Z0-9-]+\\.[a-zA-Z0-9-.]+$)\", email) else False\n",
    "\n",
    "def fix_mail_list(recipients):\n",
    "    recipients = recipients.split(' ')\n",
    "    return [email for email in recipients if is_email_valid(email)]\n",
    "\n",
    "def apk(actual, predicted, k=10):\n",
    "    if len(predicted)>k:\n",
    "        predicted = predicted[:k]\n",
    "\n",
    "    score = 0.0\n",
    "    num_hits = 0.0\n",
    "\n",
    "    for i,p in enumerate(predicted):\n",
    "        if p in actual and p not in predicted[:i]:\n",
    "            num_hits += 1.0\n",
    "            score += num_hits / (i+1.0)\n",
    "\n",
    "    if not actual:\n",
    "        return 0.0\n",
    "\n",
    "    return score / min(len(actual), k)\n",
    "\n",
    "def compute_corpus_term_idfs(corpus_features, norm_corpus):\n",
    "    \n",
    "    dfs = np.diff(sp.csc_matrix(corpus_features, copy=True).indptr)\n",
    "    dfs = 1 + dfs # to smoothen idf later\n",
    "    total_docs = 1 + len(norm_corpus)\n",
    "    idfs = 1.0 + np.log(float(total_docs) / dfs)\n",
    "    return idfs\n",
    "\n",
    "\n",
    "def compute_bm25_similarity(doc_features, corpus_features,\n",
    "                            corpus_doc_lengths, avg_doc_length,\n",
    "                            term_idfs, k1=1.5, b=0.75, top_n=3):\n",
    "    doc_features.data = np.ones(len(doc_features.data))\n",
    "    \n",
    "    doc_features = doc_features.tocsr()\n",
    "    term_idfs_sparse = csr_matrix(term_idfs)\n",
    "    doc_idfs = doc_features.multiply(term_idfs_sparse)   \n",
    "        \n",
    "    multiplicator = csr_matrix([k1 + 1])\n",
    "    numerator_coeff = corpus_features.multiply(multiplicator)\n",
    "    numerator = numerator_coeff.multiply(doc_idfs)\n",
    "        \n",
    "    denominator_coeff =  k1 * (1 - b + (b * (corpus_doc_lengths / avg_doc_length)))\n",
    "    denominator_coeff = csr_matrix(np.vstack(denominator_coeff).T)\n",
    "    \n",
    "    doc_idfs_copy = doc_idfs[:]\n",
    "    doc_idfs_copy.data = np.ones(len(doc_idfs_copy.data))\n",
    "    doc_idfs_ones = csc_matrix(doc_idfs_copy)\n",
    "        \n",
    "    f_q_D = corpus_features.multiply(doc_idfs_ones)\n",
    "    \n",
    "    doc_idfs_ones = doc_idfs_ones.transpose()\n",
    "    denominator_coeff = doc_idfs_ones.multiply(denominator_coeff).transpose()\n",
    "\n",
    "    denominator = f_q_D + denominator_coeff\n",
    "    denominator.data = 1./denominator.data\n",
    "    \n",
    "    divide = numerator.multiply(denominator)\n",
    "    bm25_scores = np.array(divide.sum(axis=1).flatten())[0]\n",
    "            \n",
    "    top_docs = bm25_scores.argsort()[::-1][:top_n]\n",
    "    top_docs_with_score = [(index, round(bm25_scores[index], 3))\n",
    "                            for index in top_docs]\n",
    "    \n",
    "    return top_docs_with_score\n",
    "\n",
    "def get_names(mail_adress):\n",
    "    match = re.findall(r'([a-z]+)\\.([a-z]+)@[a-z]+\\.[a-z]+', mail_adress)\n",
    "    if match:\n",
    "        return match[0]\n",
    "    return None\n",
    "\n",
    "def is_name_in_mail(mail, names):\n",
    "    if not names:\n",
    "        return -1\n",
    "    mail_intro = mail.split(' ')[:10]\n",
    "    return 1 if (names[0] in mail or names[1] in mail_intro) else -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### To preprocess the body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from contractions import CONTRACTION_MAP\n",
    "import re\n",
    "import nltk\n",
    "import string\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from HTMLParser import HTMLParser\n",
    "import unicodedata\n",
    "\n",
    "stopword_list = nltk.corpus.stopwords.words('english')\n",
    "stopword_list = stopword_list + ['mr', 'mrs', 'come', 'go', 'get',\n",
    "                                 'tell', 'listen', 'one', 'two', 'three',\n",
    "                                 'four', 'five', 'six', 'seven', 'eight',\n",
    "                                 'nine', 'zero', 'join', 'find', 'make',\n",
    "                                 'say', 'ask', 'tell', 'see', 'try', 'back',\n",
    "                                 'also']\n",
    "wnl = WordNetLemmatizer()\n",
    "html_parser = HTMLParser()\n",
    "\n",
    "def tokenize_text(text):\n",
    "    tokens = nltk.word_tokenize(text) \n",
    "    tokens = [token.strip() for token in tokens]\n",
    "    return tokens\n",
    "\n",
    "def expand_contractions(text, contraction_mapping):\n",
    "    \n",
    "    contractions_pattern = re.compile('({})'.format('|'.join(contraction_mapping.keys())), \n",
    "                                      flags=re.IGNORECASE|re.DOTALL)\n",
    "    def expand_match(contraction):\n",
    "        match = contraction.group(0)\n",
    "        first_char = match[0]\n",
    "        expanded_contraction = contraction_mapping.get(match)\\\n",
    "                                if contraction_mapping.get(match)\\\n",
    "                                else contraction_mapping.get(match.lower())                       \n",
    "        expanded_contraction = first_char+expanded_contraction[1:]\n",
    "        return expanded_contraction\n",
    "        \n",
    "    expanded_text = contractions_pattern.sub(expand_match, text)\n",
    "    expanded_text = re.sub(\"'\", \"\", expanded_text)\n",
    "    return expanded_text\n",
    "    \n",
    "    \n",
    "from pattern.en import tag\n",
    "from nltk.corpus import wordnet as wn\n",
    "\n",
    "# Annotate text tokens with POS tags\n",
    "def pos_tag_text(text):\n",
    "    \n",
    "    def penn_to_wn_tags(pos_tag):\n",
    "        if pos_tag.startswith('J'):\n",
    "            return wn.ADJ\n",
    "        elif pos_tag.startswith('V'):\n",
    "            return wn.VERB\n",
    "        elif pos_tag.startswith('N'):\n",
    "            return wn.NOUN\n",
    "        elif pos_tag.startswith('R'):\n",
    "            return wn.ADV\n",
    "        else:\n",
    "            return None\n",
    "    \n",
    "    tagged_text = tag(text)\n",
    "    tagged_lower_text = [(word.lower(), penn_to_wn_tags(pos_tag))\n",
    "                         for word, pos_tag in\n",
    "                         tagged_text]\n",
    "    return tagged_lower_text\n",
    "    \n",
    "# lemmatize text based on POS tags    \n",
    "def lemmatize_text(text):\n",
    "    \n",
    "    pos_tagged_text = pos_tag_text(text)\n",
    "    lemmatized_tokens = [wnl.lemmatize(word, pos_tag) if pos_tag\n",
    "                         else word                     \n",
    "                         for word, pos_tag in pos_tagged_text]\n",
    "    lemmatized_text = ' '.join(lemmatized_tokens)\n",
    "    return lemmatized_text\n",
    "    \n",
    "\n",
    "def remove_special_characters(text):\n",
    "    tokens = tokenize_text(text)\n",
    "    pattern = re.compile('[{}]'.format(re.escape(string.punctuation)))\n",
    "    filtered_tokens = filter(None, [pattern.sub(' ', token) for token in tokens])\n",
    "    filtered_text = ' '.join(filtered_tokens)\n",
    "    return filtered_text\n",
    "    \n",
    "    \n",
    "def remove_stopwords(text):\n",
    "    tokens = tokenize_text(text)\n",
    "    filtered_tokens = [token for token in tokens if token not in stopword_list]\n",
    "    filtered_text = ' '.join(filtered_tokens)    \n",
    "    return filtered_text\n",
    "\n",
    "def keep_text_characters(text):\n",
    "    filtered_tokens = []\n",
    "    tokens = tokenize_text(text)\n",
    "    for token in tokens:\n",
    "        if re.search('[a-zA-Z]', token):\n",
    "            filtered_tokens.append(token)\n",
    "    filtered_text = ' '.join(filtered_tokens)\n",
    "    return filtered_text\n",
    "\n",
    "def unescape_html(parser, text):\n",
    "    \n",
    "    return parser.unescape(text)\n",
    "\n",
    "def normalize_corpus(corpus, lemmatize=True, \n",
    "                     only_text_chars=False,\n",
    "                     tokenize=False):\n",
    "    \n",
    "    ## Log the process\n",
    "    start_time = time()\n",
    "    finish_cursor = len(corpus)\n",
    "\n",
    "    normalized_corpus = []    \n",
    "    for idx, text in enumerate(corpus):\n",
    "        if idx % 100 == 0 or idx == finish_cursor-1:\n",
    "            log_process(cursor=idx, finish_cursor=finish_cursor, start_time=start_time)\n",
    "        text = html_parser.unescape(text)\n",
    "        text = expand_contractions(text, CONTRACTION_MAP)\n",
    "        if lemmatize:\n",
    "            text = lemmatize_text(text)\n",
    "        else:\n",
    "            text = text.lower()\n",
    "        text = remove_special_characters(text)\n",
    "        text = remove_stopwords(text)\n",
    "        if only_text_chars:\n",
    "            text = keep_text_characters(text)\n",
    "        \n",
    "        if tokenize:\n",
    "            text = tokenize_text(text)\n",
    "            normalized_corpus.append(text)\n",
    "        else:\n",
    "            normalized_corpus.append(text)\n",
    "            \n",
    "    return normalized_corpus\n",
    "\n",
    "\n",
    "def parse_document(document):\n",
    "    document = re.sub('\\n', ' ', document)\n",
    "    if isinstance(document, str):\n",
    "        document = document\n",
    "    elif isinstance(document, unicode):\n",
    "        return unicodedata.normalize('NFKD', document).encode('ascii', 'ignore')\n",
    "    else:\n",
    "        raise ValueError('Document is not string or unicode!')\n",
    "    document = document.strip()\n",
    "    sentences = nltk.sent_tokenize(document)\n",
    "    sentences = [sentence.strip() for sentence in sentences]\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path_to_data = './'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##########################\n",
    "# load some of the files #                           \n",
    "##########################\n",
    "\n",
    "training = pd.read_csv(path_to_data + 'training_set.csv', sep=',', header=0)\n",
    "training_info = pd.read_csv(path_to_data + 'training_info.csv', sep=',', header=0)\n",
    "test = pd.read_csv(path_to_data + 'test_set.csv', sep=',', header=0)\n",
    "test_info = pd.read_csv(path_to_data + 'test_info.csv', sep=',', header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sender</th>\n",
       "      <th>mids</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>karen.buckley@enron.com</td>\n",
       "      <td>158713 158697 200301 158679 278595 298162 2002...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>amr.ibrahim@enron.com</td>\n",
       "      <td>215241 3437 215640 3506 191790 3517 3520 3562 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>andrea.ring@enron.com</td>\n",
       "      <td>270705 270706 270707 270708 270709 270710 2707...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sylvia.hu@enron.com</td>\n",
       "      <td>111444 111422 183084 111412 111347 110883 1105...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>phillip.platter@enron.com</td>\n",
       "      <td>327074 327384 327385 264443 274124 274125 2741...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      sender  \\\n",
       "0    karen.buckley@enron.com   \n",
       "1      amr.ibrahim@enron.com   \n",
       "2      andrea.ring@enron.com   \n",
       "3        sylvia.hu@enron.com   \n",
       "4  phillip.platter@enron.com   \n",
       "\n",
       "                                                mids  \n",
       "0  158713 158697 200301 158679 278595 298162 2002...  \n",
       "1  215241 3437 215640 3506 191790 3517 3520 3562 ...  \n",
       "2  270705 270706 270707 270708 270709 270710 2707...  \n",
       "3  111444 111422 183084 111412 111347 110883 1105...  \n",
       "4  327074 327384 327385 264443 274124 274125 2741...  "
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mid</th>\n",
       "      <th>date</th>\n",
       "      <th>body</th>\n",
       "      <th>recipients</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>60</td>\n",
       "      <td>2000-07-25 08:14:00</td>\n",
       "      <td>Legal has been assessing the risks of doing bl...</td>\n",
       "      <td>robert.badeer@enron.com murray.o neil@enron.co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>66</td>\n",
       "      <td>2000-08-03 02:56:00</td>\n",
       "      <td>Attached is a spreadsheet to estimate export f...</td>\n",
       "      <td>kim.ward@enron.com robert.badeer@enron.com mur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>74</td>\n",
       "      <td>2000-08-15 05:37:00</td>\n",
       "      <td>Kevin/Bob: Here is a quick rundown on the cons...</td>\n",
       "      <td>robert.badeer@enron.com john.massey@enron.com ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>80</td>\n",
       "      <td>2000-08-20 14:12:00</td>\n",
       "      <td>check this out and let everyone know what s up...</td>\n",
       "      <td>robert.badeer@enron.com jeff.richter@enron.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>83</td>\n",
       "      <td>2000-08-22 08:17:00</td>\n",
       "      <td>Further to your letter to us (addressed to Mr....</td>\n",
       "      <td>pgillman@schiffhardin.com kamarlantes@calpx.co...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mid                 date  \\\n",
       "0   60  2000-07-25 08:14:00   \n",
       "1   66  2000-08-03 02:56:00   \n",
       "2   74  2000-08-15 05:37:00   \n",
       "3   80  2000-08-20 14:12:00   \n",
       "4   83  2000-08-22 08:17:00   \n",
       "\n",
       "                                                body  \\\n",
       "0  Legal has been assessing the risks of doing bl...   \n",
       "1  Attached is a spreadsheet to estimate export f...   \n",
       "2  Kevin/Bob: Here is a quick rundown on the cons...   \n",
       "3  check this out and let everyone know what s up...   \n",
       "4  Further to your letter to us (addressed to Mr....   \n",
       "\n",
       "                                          recipients  \n",
       "0  robert.badeer@enron.com murray.o neil@enron.co...  \n",
       "1  kim.ward@enron.com robert.badeer@enron.com mur...  \n",
       "2  robert.badeer@enron.com john.massey@enron.com ...  \n",
       "3     robert.badeer@enron.com jeff.richter@enron.com  \n",
       "4  pgillman@schiffhardin.com kamarlantes@calpx.co...  "
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_info.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sender</th>\n",
       "      <th>mids</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>karen.buckley@enron.com</td>\n",
       "      <td>298389 332383 298390 284071 366982 81773 81791...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>amr.ibrahim@enron.com</td>\n",
       "      <td>48260 48465 50344 48268 50330 48237 189979 189...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>andrea.ring@enron.com</td>\n",
       "      <td>366364 271168 271172 271167 271189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sylvia.hu@enron.com</td>\n",
       "      <td>134931 134856 233549 233517 134895 233584 3736...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>phillip.platter@enron.com</td>\n",
       "      <td>274220 274225 274215 274223 274214 274207 2742...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      sender  \\\n",
       "0    karen.buckley@enron.com   \n",
       "1      amr.ibrahim@enron.com   \n",
       "2      andrea.ring@enron.com   \n",
       "3        sylvia.hu@enron.com   \n",
       "4  phillip.platter@enron.com   \n",
       "\n",
       "                                                mids  \n",
       "0  298389 332383 298390 284071 366982 81773 81791...  \n",
       "1  48260 48465 50344 48268 50330 48237 189979 189...  \n",
       "2                 366364 271168 271172 271167 271189  \n",
       "3  134931 134856 233549 233517 134895 233584 3736...  \n",
       "4  274220 274225 274215 274223 274214 274207 2742...  "
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mid</th>\n",
       "      <th>date</th>\n",
       "      <th>body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1577</td>\n",
       "      <td>2001-11-19 06:59:51</td>\n",
       "      <td>Note:  Stocks of heating oil are very high for...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1750</td>\n",
       "      <td>2002-03-05 08:46:57</td>\n",
       "      <td>Kevin Hyatt and I are going for \"sghetti\" at S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1916</td>\n",
       "      <td>2002-02-13 14:17:39</td>\n",
       "      <td>This was forwarded to me and it is funny. - Wi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2094</td>\n",
       "      <td>2002-01-22 11:33:56</td>\n",
       "      <td>I will be in to and happy to assist too.  I ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2205</td>\n",
       "      <td>2002-01-11 07:12:19</td>\n",
       "      <td>Thanks. I needed a morning chuckle.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mid                 date  \\\n",
       "0  1577  2001-11-19 06:59:51   \n",
       "1  1750  2002-03-05 08:46:57   \n",
       "2  1916  2002-02-13 14:17:39   \n",
       "3  2094  2002-01-22 11:33:56   \n",
       "4  2205  2002-01-11 07:12:19   \n",
       "\n",
       "                                                body  \n",
       "0  Note:  Stocks of heating oil are very high for...  \n",
       "1  Kevin Hyatt and I are going for \"sghetti\" at S...  \n",
       "2  This was forwarded to me and it is funny. - Wi...  \n",
       "3  I will be in to and happy to assist too.  I ma...  \n",
       "4                Thanks. I needed a morning chuckle.  "
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_info.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_messages_written_by_u_to_c(u=None, \n",
    "                                   c=None, \n",
    "                                   t_init=None, \n",
    "                                   t_final=None, \n",
    "                                   t_init_include=True,\n",
    "                                   t_final_include=True,\n",
    "                                   set_=training, \n",
    "                                   set_info=training_info):\n",
    "    \"\"\"\n",
    "    This function makes it possible to retrieve all the ids of the messages sent BY u to c, where u and c are mail addresses (String)\n",
    "    If u = None, then all messages sent to c, regardless of the sender\n",
    "    If c = None, then we get all messages sent PAR u, whatever the receiver\n",
    "    If u = None and c = None, we get all messages ...\n",
    "    One can choose a time filter by imposing a minimum date (t_init) and a maximum date (t_final)\n",
    "    You can optionally include or exclude these dates via t_init_include, t_final_include.\n",
    "    Finally, we can work with simplified dates (YYYY-MM-DD) or complete (YYYY-MM-DD hh: mm: ss)\n",
    "    Example:\n",
    "    --------\n",
    "    Get_messages_written_by_u_to_c (u='andrea.ring@enron.com ',\n",
    "                                   C='amr.ibrahim@enron.com ',\n",
    "                                   T_init = '1990-04-01',\n",
    "                                   T_final = '2000-02-13 23:12:00')\n",
    "    Returns all message identifiers sent by andrea.ring@enron.com to amr.ibrahim@enron.com between the\n",
    "    1 April 1990 (included - by default) and 13 February 2000, 23h12min00sec (included - by default).    \n",
    "    \"\"\"\n",
    "    try: \n",
    "        # mids of messages sent by u\n",
    "        mids = list(map(int, set_[set_['sender'] == u]['mids'].values[0].split(' '))) if u else None\n",
    "        # Filter messages by mid\n",
    "        set_info_filtered = set_info[set_info['mid'].isin(mids)] if u else set_info\n",
    "        # Filter messages by time (t_init)\n",
    "        set_info_filtered = set_info_filtered[(ge if t_init_include else gt)(set_info_filtered['date_simplified' if len(t_init)==10 else 'date'], t_init)] if t_init else set_info_filtered\n",
    "        # Filter messages by time (t_final)\n",
    "        set_info_filtered = set_info_filtered[(le if t_final_include else lt)(set_info_filtered['date_simplified' if len(t_final)==10 else 'date'], t_final)] if t_final else set_info_filtered\n",
    "        # Filter by recipient\n",
    "        set_info_filtered = set_info_filtered[set_info_filtered['recipients_valid'].map(lambda recipients: c in recipients)] if c else set_info_filtered \n",
    "        # Return mids of relevant messages\n",
    "        return set_info_filtered.mid.values\n",
    "    except: # If an exeption is raised, it's because no message was found, in this case, we just return an empty array.\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Carnet d'adresse des senders pour les dates indiquées\n",
    "def create_handbook(set_=training, set_info=training_info, t_final=None, t_init=None, t_init_include=True, t_final_include=False):\n",
    "    all_senders = set_.sender.values\n",
    "    d = {}\n",
    "    for sender in all_senders:\n",
    "        sent_by_sender = get_messages_written_by_u_to_c(u=sender, t_init=t_init, t_final=t_final, t_init_include=t_init_include, t_final_include=t_final_include)\n",
    "        sent_to_sender = get_messages_written_by_u_to_c(c=sender, t_init=t_init, t_final=t_final, t_init_include=t_init_include, t_final_include=t_final_include)\n",
    "        recipients = []\n",
    "        # Emails de ceux qui ont reçu un mail de sender\n",
    "        for rec_list in set_info[set_info.mid.isin(map(int, sent_by_sender))].recipients_valid:\n",
    "            for rec in rec_list:\n",
    "                recipients.append(rec)\n",
    "        # Emails de ceux qui ont envoyé un mail à sender\n",
    "        for mid in map(str, sent_to_sender):\n",
    "            recipients.append(map_mid_to_sender[int(mid)])\n",
    "        recipients = set(recipients)\n",
    "        d[sender] = recipients\n",
    "    return d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We add date_simplified and we correct date with bad format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training_info['date_simplified'] = training_info.date.map(simplify_date)\n",
    "test_info['date_simplified'] = test_info.date.map(simplify_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training_info.date_simplified = training_info.date_simplified.map(lambda x: x if x[0] != '0' else '2' + x[1:])\n",
    "training_info.date = training_info.date.map(lambda x: x if x[0] != '0' else '2' + x[1:])\n",
    "test_info.date_simplified = test_info.date_simplified.map(lambda x: x if x[0] != '0' else '2' + x[1:])\n",
    "test_info.date = test_info.date.map(lambda x: x if x[0] != '0' else '2' + x[1:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We sort training_info and test_info by date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training_info.sort_values('date_simplified', inplace=True)\n",
    "test_info.sort_values('date_simplified', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We correct email with bad format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "training_info['recipients_valid'] = training_info.recipients.map(fix_mail_list)\n",
    "training.sender = training.sender.map(fix_mail_list).map(lambda sender_list: sender_list[0])\n",
    "test.sender = test.sender.map(fix_mail_list).map(lambda sender_list: sender_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "recipients = []\n",
    "for recipient_list in training_info['recipients_valid']:\n",
    "    for recipient in recipient_list:\n",
    "        recipients.append(recipient)\n",
    "unique_recipients = set(recipients)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Some useful dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "map_mid_to_date = {}\n",
    "for row in training_info.iterrows():\n",
    "    map_mid_to_date[row[1].mid] = row[1].date\n",
    "    \n",
    "for row in test_info.iterrows():\n",
    "    map_mid_to_date[row[1].mid] = row[1].date\n",
    "\n",
    "map_mid_to_sender = {}\n",
    "for d in training.apply(lambda x: {int(mid): x.sender for mid in x.mids.split(' ')}, axis=1).values:\n",
    "    map_mid_to_sender.update(d)\n",
    "    \n",
    "map_mid_to_receiver = {}\n",
    "for row in training_info.iterrows():\n",
    "    map_mid_to_receiver[row[1].mid] = row[1].recipients_valid\n",
    "\n",
    "map_sender_to_mid = {}\n",
    "for sender in training.sender:\n",
    "    map_sender_to_mid[sender] = training[training.sender==sender].mids.values[0].split(' ')\n",
    "    \n",
    "map_sender_to_mid_w_date = defaultdict(list)\n",
    "for sender in training.sender:\n",
    "    for mid in map_sender_to_mid[sender]:\n",
    "        map_sender_to_mid_w_date[sender].append((mid, map_mid_to_date[int(mid)]))\n",
    "        \n",
    "for recipient in map_sender_to_mid_w_date.keys():\n",
    "    map_sender_to_mid_w_date[recipient] = sorted(map_sender_to_mid_w_date[recipient], key=lambda x: x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "NB_SPLIT = 5\n",
    "mids_train_test = []\n",
    "for i in range(NB_SPLIT):\n",
    "    new_split = { 'train': [], 'test': [] }\n",
    "    for recipient in map_sender_to_mid_w_date.keys():\n",
    "        idx_lim_inf = (NB_SPLIT - i)*10\n",
    "        \n",
    "        idx_lim_sup = (i - (NB_SPLIT-1))*10 if ((NB_SPLIT-1) - i)*10 != 0 else None\n",
    "        new_split['train'] += [x[0] for x in map_sender_to_mid_w_date[recipient][:-idx_lim_inf]]\n",
    "        new_split['test'] += [x[0] for x in map_sender_to_mid_w_date[recipient][-idx_lim_inf:idx_lim_sup]]\n",
    "    mids_train_test.append(new_split)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Body preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "training_info['body_normalized'] = np.array(normalize_corpus(training_info.body, lemmatize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_info['body_normalized'] = np.array(normalize_corpus(test_info.body, lemmatize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training_info.to_csv('./training_info_df.csv', encoding='utf-8')\n",
    "test_info.to_csv('./test_info_df.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#training_info = pd.read_csv('./training_info_df.csv', encoding='utf-8')\n",
    "#training_info.drop(['Unnamed: 0'], axis=1, inplace=True)\n",
    "#training_info.mid = training_info.mid.map(lambda x: int(x))\n",
    "#training_info.body_normalized = training_info.body_normalized.map(lambda x: '' if type(x)==float else x)\n",
    "#training_info['recipients_valid'] = training_info.recipients.map(fix_mail_list)\n",
    "#test_info = pd.read_csv('./test_info_df.csv', encoding='utf-8')\n",
    "#test_info.drop(['Unnamed: 0'], axis=1, inplace=True)\n",
    "#test_info.mid = test_info.mid.map(lambda x: int(x))\n",
    "#test_info.body_normalized = test_info.body_normalized.map(lambda x: '' if type(x)==float else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mid</th>\n",
       "      <th>date</th>\n",
       "      <th>body</th>\n",
       "      <th>date_simplified</th>\n",
       "      <th>body_normalized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>204747</td>\n",
       "      <td>2001-11-02 07:47:19</td>\n",
       "      <td>GWF ???</td>\n",
       "      <td>2001-11-02</td>\n",
       "      <td>gwf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>82354</td>\n",
       "      <td>2001-11-02 06:17:44</td>\n",
       "      <td>WOW.... I am positive that your beautiful wife...</td>\n",
       "      <td>2001-11-02</td>\n",
       "      <td>wow positive beautiful wife sign haul rug rat ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>101099</td>\n",
       "      <td>2001-11-02 14:31:15</td>\n",
       "      <td>The following name overlay was completed in GC...</td>\n",
       "      <td>2001-11-02</td>\n",
       "      <td>following name overlay complete gcp today cp i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>160740</td>\n",
       "      <td>2001-11-02 10:44:50</td>\n",
       "      <td>-----Original Message-----From: Legler, Micha...</td>\n",
       "      <td>2001-11-02</td>\n",
       "      <td>original message legler michael j send tuesday...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>200363</td>\n",
       "      <td>2001-11-02 11:12:37</td>\n",
       "      <td>-----Original Message-----From: \\tVan houten,...</td>\n",
       "      <td>2001-11-02</td>\n",
       "      <td>original message van houten maria send friday ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      mid                 date  \\\n",
       "0  204747  2001-11-02 07:47:19   \n",
       "1   82354  2001-11-02 06:17:44   \n",
       "2  101099  2001-11-02 14:31:15   \n",
       "3  160740  2001-11-02 10:44:50   \n",
       "4  200363  2001-11-02 11:12:37   \n",
       "\n",
       "                                                body date_simplified  \\\n",
       "0                                          GWF ???        2001-11-02   \n",
       "1  WOW.... I am positive that your beautiful wife...      2001-11-02   \n",
       "2  The following name overlay was completed in GC...      2001-11-02   \n",
       "3   -----Original Message-----From: Legler, Micha...      2001-11-02   \n",
       "4   -----Original Message-----From: \\tVan houten,...      2001-11-02   \n",
       "\n",
       "                                     body_normalized  \n",
       "0                                                gwf  \n",
       "1  wow positive beautiful wife sign haul rug rat ...  \n",
       "2  following name overlay complete gcp today cp i...  \n",
       "3  original message legler michael j send tuesday...  \n",
       "4  original message van houten maria send friday ...  "
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_info.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pleins de trucs qui servent à calculer BM25 et construire les features textuels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tfidf_vectorizer, tfidf_features = build_feature_matrix(training_info['body_normalized'],\n",
    "                                                        feature_type='tfidf',\n",
    "                                                        ngram_range=(1, 1), \n",
    "                                                        min_df=3, max_df=1.0)\n",
    "query_docs_tfidf = tfidf_vectorizer.transform(test_info['body_normalized'])\n",
    "vectorizer, corpus_features = build_feature_matrix(training_info['body_normalized'],\n",
    "                                                   feature_type='frequency')\n",
    "query_docs_features = vectorizer.transform(test_info['body_normalized'])\n",
    "doc_lengths = [len(doc.split()) for doc in training_info['body_normalized']]   \n",
    "avg_dl = np.average(doc_lengths)\n",
    "corpus_term_idfs = compute_corpus_term_idfs(corpus_features, training_info['body_normalized'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Address book creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "handbook_train = create_handbook(set_=training, set_info=training_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Features temporels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_last_message_from_u_to_c(u, c, t):\n",
    "    previous_mails = get_messages_written_by_u_to_c(u=u, c=c, t_final=t, t_final_include=False)\n",
    "    return map_mid_to_date[previous_mails[-1]] if list(previous_mails) else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def outgoing_message_percentage(u, c, t):\n",
    "    try:\n",
    "        return len(get_messages_written_by_u_to_c(u=u, c=c, t_init=None, t_final=t, t_final_include=False))/\\\n",
    "               len(get_messages_written_by_u_to_c(u=u, c=None, t_init=None, t_final=t, t_final_include=False))\n",
    "    except:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def incoming_message_percentage(u, c, t):\n",
    "    try:\n",
    "        return len(get_messages_written_by_u_to_c(u=c, c=u, t_init=None, t_final=t, t_final_include=False))/\\\n",
    "               len(get_messages_written_by_u_to_c(u=None, c=u, t_init=None, t_final=t, t_final_include=False))\n",
    "    except:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def more_recent_outgoing_percentage(u, c, t, alpha=2):\n",
    "    t_init = get_last_message_from_u_to_c(u=u, c=c, t=t)\n",
    "    try: \n",
    "        return (1./alpha)*len(get_messages_written_by_u_to_c(u=u, c=None, t_init=t_init, t_final=t, t_final_include=False))/\\\n",
    "                          len(get_messages_written_by_u_to_c(u=u, c=None, t_init=0, t_final=t, t_final_include=False))\n",
    "    except:\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def more_recent_incoming_percentage(u, c, t, alpha=2):\n",
    "    t_init = get_last_message_from_u_to_c(u=c, c=u, t=t)\n",
    "    try:\n",
    "        return (1./alpha)*len(get_messages_written_by_u_to_c(u=None, c=u, t_init=t_init, t_final=t, t_final_include=False))/\\\n",
    "                          len(get_messages_written_by_u_to_c(u=None, c=u, t_init=0, t_final=t, t_final_include=False))\n",
    "    except:\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We look for most similar email body for each email in test and training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "similar_docs = []\n",
    "\n",
    "# Log the process\n",
    "start_time = time()\n",
    "finish_cursor = len(test_info['body_normalized'])\n",
    "\n",
    "for index, doc in enumerate(test_info['body_normalized']):\n",
    "    \n",
    "    doc_features = query_docs_features[index]\n",
    "    top_similar_docs = compute_bm25_similarity(doc_features,\n",
    "                                               corpus_features,\n",
    "                                               doc_lengths,\n",
    "                                               avg_dl,\n",
    "                                               corpus_term_idfs,\n",
    "                                               k1=1.5, b=0.75,\n",
    "                                               top_n=30)\n",
    "        \n",
    "    log_process(cursor=index, finish_cursor=finish_cursor, start_time=start_time)\n",
    "\n",
    "    similar_docs.append(top_similar_docs)\n",
    "    \n",
    "    if index % 10 == 0 or index == finish_cursor - 1:\n",
    "        similarity = pd.DataFrame(similar_docs)\n",
    "        similarity.to_csv('./similarity_test_indo.csv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "query_docs_tfidf_train = tfidf_vectorizer.transform(training_info['body_normalized'])\n",
    "query_docs_features_train = vectorizer.transform(training_info['body_normalized'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "similar_docs_train = []\n",
    "# Log the process\n",
    "start_time = time()\n",
    "finish_cursor = len(training_info['body_normalized'])\n",
    "for index, doc in enumerate(training_info['body_normalized']):\n",
    "    \n",
    "    \n",
    "    doc_features = query_docs_features_train[index]\n",
    "    top_similar_docs = compute_bm25_similarity(doc_features,\n",
    "                                               corpus_features,\n",
    "                                               doc_lengths,\n",
    "                                               avg_dl,\n",
    "                                               corpus_term_idfs,\n",
    "                                               k1=1.5, b=0.75,\n",
    "                                               top_n=31)\n",
    "        \n",
    "    log_process(cursor=index, finish_cursor=finish_cursor, start_time=start_time)\n",
    "\n",
    "    similar_docs_train.append(top_similar_docs)\n",
    "    \n",
    "    if index % 500 == 0 or index == finish_cursor - 1:\n",
    "        similarity_train = pd.DataFrame(similar_docs_train)\n",
    "        similarity_train.to_csv('./similarity_train_indo.csv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "similarity_train.drop([0], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#similarity_train = pd.read_csv('./similarity_train_indo.csv', sep='\\t')\n",
    "#similarity_train.drop(['0', 'Unnamed: 0'], axis=1, inplace=True)\n",
    "#similarity_train = similarity_train.applymap(lambda a: tuple(int(x) if idx==0 else float(x) for idx, x in enumerate(a[1:-1].split(', '))))\n",
    "#similarity = pd.read_csv('./similarity_test_indo.csv', sep='\\t')\n",
    "#similarity.drop(['Unnamed: 0'], axis=1, inplace=True)\n",
    "#similarity = similarity.applymap(lambda a: tuple(int(x) if idx==0 else float(x) for idx, x in enumerate(a[1:-1].split(', '))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(14009, 92.424)</td>\n",
       "      <td>(13663, 85.452)</td>\n",
       "      <td>(4883, 81.997)</td>\n",
       "      <td>(4157, 79.816)</td>\n",
       "      <td>(5544, 79.572)</td>\n",
       "      <td>(1859, 78.309)</td>\n",
       "      <td>(4882, 77.303)</td>\n",
       "      <td>(2364, 76.558)</td>\n",
       "      <td>(1272, 75.967)</td>\n",
       "      <td>(26562, 75.124)</td>\n",
       "      <td>...</td>\n",
       "      <td>(13844, 69.783)</td>\n",
       "      <td>(3833, 69.748)</td>\n",
       "      <td>(5177, 69.363)</td>\n",
       "      <td>(11049, 69.116)</td>\n",
       "      <td>(9419, 68.837)</td>\n",
       "      <td>(10850, 68.252)</td>\n",
       "      <td>(13829, 68.236)</td>\n",
       "      <td>(3995, 68.149)</td>\n",
       "      <td>(9467, 67.809)</td>\n",
       "      <td>(4200, 67.661)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(20819, 95.252)</td>\n",
       "      <td>(11766, 95.238)</td>\n",
       "      <td>(11749, 95.238)</td>\n",
       "      <td>(33675, 95.235)</td>\n",
       "      <td>(24010, 94.556)</td>\n",
       "      <td>(24021, 94.556)</td>\n",
       "      <td>(29305, 92.853)</td>\n",
       "      <td>(29276, 92.853)</td>\n",
       "      <td>(35980, 91.968)</td>\n",
       "      <td>(35974, 91.968)</td>\n",
       "      <td>...</td>\n",
       "      <td>(27220, 88.295)</td>\n",
       "      <td>(36537, 87.929)</td>\n",
       "      <td>(36664, 87.929)</td>\n",
       "      <td>(36583, 87.929)</td>\n",
       "      <td>(36498, 87.929)</td>\n",
       "      <td>(2544, 87.303)</td>\n",
       "      <td>(26415, 87.25)</td>\n",
       "      <td>(19550, 87.227)</td>\n",
       "      <td>(17111, 86.448)</td>\n",
       "      <td>(41039, 86.423)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(351, 128.683)</td>\n",
       "      <td>(4513, 126.78)</td>\n",
       "      <td>(17724, 125.077)</td>\n",
       "      <td>(17787, 125.077)</td>\n",
       "      <td>(615, 122.979)</td>\n",
       "      <td>(17522, 121.551)</td>\n",
       "      <td>(17500, 121.551)</td>\n",
       "      <td>(3872, 119.23)</td>\n",
       "      <td>(3875, 119.23)</td>\n",
       "      <td>(613, 116.276)</td>\n",
       "      <td>...</td>\n",
       "      <td>(33380, 105.929)</td>\n",
       "      <td>(33457, 105.929)</td>\n",
       "      <td>(16835, 103.087)</td>\n",
       "      <td>(33393, 101.171)</td>\n",
       "      <td>(33442, 101.171)</td>\n",
       "      <td>(34651, 99.952)</td>\n",
       "      <td>(34643, 99.952)</td>\n",
       "      <td>(16206, 99.097)</td>\n",
       "      <td>(16289, 99.097)</td>\n",
       "      <td>(731, 98.961)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(4, 391.578)</td>\n",
       "      <td>(5689, 164.238)</td>\n",
       "      <td>(5676, 164.238)</td>\n",
       "      <td>(4189, 115.327)</td>\n",
       "      <td>(4161, 115.327)</td>\n",
       "      <td>(435, 102.455)</td>\n",
       "      <td>(85, 97.22)</td>\n",
       "      <td>(84, 97.22)</td>\n",
       "      <td>(18955, 89.227)</td>\n",
       "      <td>(28653, 87.428)</td>\n",
       "      <td>...</td>\n",
       "      <td>(3087, 61.505)</td>\n",
       "      <td>(4958, 59.211)</td>\n",
       "      <td>(750, 55.763)</td>\n",
       "      <td>(753, 55.763)</td>\n",
       "      <td>(16289, 53.046)</td>\n",
       "      <td>(16206, 53.046)</td>\n",
       "      <td>(88, 52.441)</td>\n",
       "      <td>(89, 52.441)</td>\n",
       "      <td>(5230, 50.344)</td>\n",
       "      <td>(17500, 50.14)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(4, 391.578)</td>\n",
       "      <td>(5689, 164.238)</td>\n",
       "      <td>(5676, 164.238)</td>\n",
       "      <td>(4189, 115.327)</td>\n",
       "      <td>(4161, 115.327)</td>\n",
       "      <td>(435, 102.455)</td>\n",
       "      <td>(85, 97.22)</td>\n",
       "      <td>(84, 97.22)</td>\n",
       "      <td>(18955, 89.227)</td>\n",
       "      <td>(28653, 87.428)</td>\n",
       "      <td>...</td>\n",
       "      <td>(3087, 61.505)</td>\n",
       "      <td>(4958, 59.211)</td>\n",
       "      <td>(750, 55.763)</td>\n",
       "      <td>(753, 55.763)</td>\n",
       "      <td>(16289, 53.046)</td>\n",
       "      <td>(16206, 53.046)</td>\n",
       "      <td>(88, 52.441)</td>\n",
       "      <td>(89, 52.441)</td>\n",
       "      <td>(5230, 50.344)</td>\n",
       "      <td>(17500, 50.14)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 1                2                 3                 4  \\\n",
       "0  (14009, 92.424)  (13663, 85.452)    (4883, 81.997)    (4157, 79.816)   \n",
       "1  (20819, 95.252)  (11766, 95.238)   (11749, 95.238)   (33675, 95.235)   \n",
       "2   (351, 128.683)   (4513, 126.78)  (17724, 125.077)  (17787, 125.077)   \n",
       "3     (4, 391.578)  (5689, 164.238)   (5676, 164.238)   (4189, 115.327)   \n",
       "4     (4, 391.578)  (5689, 164.238)   (5676, 164.238)   (4189, 115.327)   \n",
       "\n",
       "                 5                 6                 7                8  \\\n",
       "0   (5544, 79.572)    (1859, 78.309)    (4882, 77.303)   (2364, 76.558)   \n",
       "1  (24010, 94.556)   (24021, 94.556)   (29305, 92.853)  (29276, 92.853)   \n",
       "2   (615, 122.979)  (17522, 121.551)  (17500, 121.551)   (3872, 119.23)   \n",
       "3  (4161, 115.327)    (435, 102.455)       (85, 97.22)      (84, 97.22)   \n",
       "4  (4161, 115.327)    (435, 102.455)       (85, 97.22)      (84, 97.22)   \n",
       "\n",
       "                 9               10       ...                       21  \\\n",
       "0   (1272, 75.967)  (26562, 75.124)       ...          (13844, 69.783)   \n",
       "1  (35980, 91.968)  (35974, 91.968)       ...          (27220, 88.295)   \n",
       "2   (3875, 119.23)   (613, 116.276)       ...         (33380, 105.929)   \n",
       "3  (18955, 89.227)  (28653, 87.428)       ...           (3087, 61.505)   \n",
       "4  (18955, 89.227)  (28653, 87.428)       ...           (3087, 61.505)   \n",
       "\n",
       "                 22                23                24                25  \\\n",
       "0    (3833, 69.748)    (5177, 69.363)   (11049, 69.116)    (9419, 68.837)   \n",
       "1   (36537, 87.929)   (36664, 87.929)   (36583, 87.929)   (36498, 87.929)   \n",
       "2  (33457, 105.929)  (16835, 103.087)  (33393, 101.171)  (33442, 101.171)   \n",
       "3    (4958, 59.211)     (750, 55.763)     (753, 55.763)   (16289, 53.046)   \n",
       "4    (4958, 59.211)     (750, 55.763)     (753, 55.763)   (16289, 53.046)   \n",
       "\n",
       "                26               27               28               29  \\\n",
       "0  (10850, 68.252)  (13829, 68.236)   (3995, 68.149)   (9467, 67.809)   \n",
       "1   (2544, 87.303)   (26415, 87.25)  (19550, 87.227)  (17111, 86.448)   \n",
       "2  (34651, 99.952)  (34643, 99.952)  (16206, 99.097)  (16289, 99.097)   \n",
       "3  (16206, 53.046)     (88, 52.441)     (89, 52.441)   (5230, 50.344)   \n",
       "4  (16206, 53.046)     (88, 52.441)     (89, 52.441)   (5230, 50.344)   \n",
       "\n",
       "                30  \n",
       "0   (4200, 67.661)  \n",
       "1  (41039, 86.423)  \n",
       "2    (731, 98.961)  \n",
       "3   (17500, 50.14)  \n",
       "4   (17500, 50.14)  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarity_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "map_mid_to_sim_train = {}\n",
    "for index, mid in enumerate(training_info['mid']):\n",
    "    map_mid_to_sim_train[mid] = filter(lambda x: x[1] > 0, similarity_train.loc[index].values[:30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "map_mid_to_sim = {}\n",
    "for index, mid in enumerate(test_info['mid']):\n",
    "    map_mid_to_sim[mid] = filter(lambda x: x[1] > 0, similarity.loc[index].values[:30])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Features textuels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def outgoing_textual_similarity(mid, c):\n",
    "    most_sim_ids = map(lambda x: x[0], map_mid_to_sim[int(mid)])\n",
    "    for idx_mail in most_sim_ids:\n",
    "        most_sim_id = training_info.iloc[idx_mail].mid\n",
    "        if c in map_mid_to_receiver[int(most_sim_id)]:\n",
    "            return 1\n",
    "    return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def incoming_textual_similarity(mid, c):\n",
    "    most_sim_ids = map(lambda x: x[0], map_mid_to_sim[int(mid)])\n",
    "    for idx_mail in most_sim_ids:\n",
    "        most_sim_id = training_info.iloc[idx_mail].mid\n",
    "        if c == map_mid_to_sender[int(most_sim_id)]:\n",
    "            return 1\n",
    "    return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def outgoing_textual_similarity_train(mid, c):\n",
    "    most_sim_ids = map(lambda x: x[0], map_mid_to_sim_train[int(mid)])\n",
    "    for idx_mail in most_sim_ids:\n",
    "        most_sim_id = training_info.iloc[idx_mail].mid\n",
    "        if c in map_mid_to_receiver[int(most_sim_id)]:\n",
    "            return 1\n",
    "    return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def incoming_textual_similarity_train(mid, c):\n",
    "    most_sim_ids = map(lambda x: x[0], map_mid_to_sim_train[int(mid)])\n",
    "    for idx_mail in most_sim_ids:\n",
    "        most_sim_id = training_info.iloc[idx_mail].mid\n",
    "        if c == map_mid_to_sender[int(most_sim_id)]:\n",
    "            return 1\n",
    "    return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_names(mail_address):\n",
    "    match = re.findall(r'(?:([a-z]+)\\.([a-z]+)|([a-z]+)\\.\\.([a-z]+)|([a-z]+))@[a-z]+\\.[a-z]+', mail_address)\n",
    "    if match:\n",
    "        return [elmt.lower() for elmt in match[0] if elmt and len(elmt) > 2] \n",
    "    return None\n",
    "    \n",
    "def is_name_in_mail(mail, names):\n",
    "    if not names:\n",
    "        return -1\n",
    "    return 1 if sum([name in mail for name in names]) else -1\n",
    "\n",
    "def is_name_in_mail_short(mail, names):\n",
    "    if not names:\n",
    "        return -1\n",
    "    return 1 if sum([name in mail[:30] for name in names]) else -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "counter_email_per_u = defaultdict(int)\n",
    "counter_from_u_to_c = defaultdict(lambda: defaultdict(int))\n",
    "for sender in training.sender:\n",
    "    mids_sender = training[training.sender==sender].mids.values[0].split(' ')\n",
    "    for mid in mids_sender:\n",
    "        counter_email_per_u[sender] += 1\n",
    "        for recipient in map_mid_to_receiver[int(mid)]:\n",
    "            counter_from_u_to_c[sender][recipient] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "freq_from_u_to_c = defaultdict(lambda: defaultdict(float))\n",
    "for sender in training.sender:\n",
    "    for recipient in counter_from_u_to_c[sender].keys():\n",
    "        freq_from_u_to_c[sender][recipient] = counter_from_u_to_c[sender][recipient]/counter_email_per_u[sender]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#train_df_w_features = pd.read_csv('./train___.csv', sep='\\t')\n",
    "#test_df_w_features  = pd.read_csv('./test___.csv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#train_df_w_features = train_df_w_features.drop(['Unnamed: 0'], axis=1)\n",
    "#test_df_w_features = test_df_w_features.drop(['Unnamed: 0'], axis=1)\n",
    "train_df_w_features.mid = train_df_w_features.mid.map(lambda mid: int(mid))\n",
    "test_df_w_features.mid = test_df_w_features.mid.map(lambda mid: int(mid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>outgoing_message_percentage</th>\n",
       "      <th>incoming_message_percentage</th>\n",
       "      <th>more_recent_outgoing_percentage</th>\n",
       "      <th>more_recent_incoming_percentage</th>\n",
       "      <th>outgoing_textual_similarity</th>\n",
       "      <th>incoming_textual_similarity</th>\n",
       "      <th>is_name_in_mail</th>\n",
       "      <th>is_name_in_mail_short_</th>\n",
       "      <th>recipient</th>\n",
       "      <th>mid</th>\n",
       "      <th>sender</th>\n",
       "      <th>result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>jason.wolfe@enron.com</td>\n",
       "      <td>158713</td>\n",
       "      <td>karen.buckley@enron.com</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>hicham.benjelloun@enron.com</td>\n",
       "      <td>158713</td>\n",
       "      <td>karen.buckley@enron.com</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>elizabeth.shim@enron.com</td>\n",
       "      <td>158697</td>\n",
       "      <td>karen.buckley@enron.com</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>elizabeth.johnston@enron.com</td>\n",
       "      <td>158697</td>\n",
       "      <td>karen.buckley@enron.com</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>russell.ballato@enron.com</td>\n",
       "      <td>158697</td>\n",
       "      <td>karen.buckley@enron.com</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   outgoing_message_percentage  incoming_message_percentage  \\\n",
       "0                          0.0                          0.0   \n",
       "1                          0.0                          0.0   \n",
       "2                          0.0                          0.0   \n",
       "3                          0.0                          0.0   \n",
       "4                          0.0                          0.0   \n",
       "\n",
       "   more_recent_outgoing_percentage  more_recent_incoming_percentage  \\\n",
       "0                              1.0                              0.5   \n",
       "1                              1.0                              0.5   \n",
       "2                              0.5                              0.5   \n",
       "3                              0.5                              0.5   \n",
       "4                              0.5                              0.5   \n",
       "\n",
       "   outgoing_textual_similarity  incoming_textual_similarity  is_name_in_mail  \\\n",
       "0                          1.0                         -1.0              1.0   \n",
       "1                         -1.0                         -1.0             -1.0   \n",
       "2                          1.0                         -1.0             -1.0   \n",
       "3                         -1.0                         -1.0             -1.0   \n",
       "4                          1.0                         -1.0             -1.0   \n",
       "\n",
       "   is_name_in_mail_short_                     recipient     mid  \\\n",
       "0                     1.0         jason.wolfe@enron.com  158713   \n",
       "1                    -1.0   hicham.benjelloun@enron.com  158713   \n",
       "2                    -1.0      elizabeth.shim@enron.com  158697   \n",
       "3                    -1.0  elizabeth.johnston@enron.com  158697   \n",
       "4                    -1.0     russell.ballato@enron.com  158697   \n",
       "\n",
       "                    sender  result  \n",
       "0  karen.buckley@enron.com     1.0  \n",
       "1  karen.buckley@enron.com    -1.0  \n",
       "2  karen.buckley@enron.com     1.0  \n",
       "3  karen.buckley@enron.com    -1.0  \n",
       "4  karen.buckley@enron.com     1.0  "
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df_w_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>outgoing_message_percentage</th>\n",
       "      <th>incoming_message_percentage</th>\n",
       "      <th>more_recent_outgoing_percentage</th>\n",
       "      <th>more_recent_incoming_percentage</th>\n",
       "      <th>outgoing_textual_similarity</th>\n",
       "      <th>incoming_textual_similarity</th>\n",
       "      <th>is_name_in_mail</th>\n",
       "      <th>is_name_in_mail_short_</th>\n",
       "      <th>recipient</th>\n",
       "      <th>mid</th>\n",
       "      <th>sender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00641</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.471154</td>\n",
       "      <td>0.5</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>karen.herrmann@enron.com</td>\n",
       "      <td>298389</td>\n",
       "      <td>karen.buckley@enron.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.00641</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.471154</td>\n",
       "      <td>0.5</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>jennifer.mcquade@enron.com</td>\n",
       "      <td>298389</td>\n",
       "      <td>karen.buckley@enron.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.00641</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.471154</td>\n",
       "      <td>0.5</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>john.hudson@enron.com</td>\n",
       "      <td>298389</td>\n",
       "      <td>karen.buckley@enron.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.00641</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.471154</td>\n",
       "      <td>0.5</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>reginald.smith@enron.com</td>\n",
       "      <td>298389</td>\n",
       "      <td>karen.buckley@enron.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.00641</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.471154</td>\n",
       "      <td>0.5</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>malley@enron.com</td>\n",
       "      <td>298389</td>\n",
       "      <td>karen.buckley@enron.com</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   outgoing_message_percentage  incoming_message_percentage  \\\n",
       "0                      0.00641                          0.0   \n",
       "1                      0.00641                          0.0   \n",
       "2                      0.00641                          0.0   \n",
       "3                      0.00641                          0.0   \n",
       "4                      0.00641                          0.0   \n",
       "\n",
       "   more_recent_outgoing_percentage  more_recent_incoming_percentage  \\\n",
       "0                         0.471154                              0.5   \n",
       "1                         0.471154                              0.5   \n",
       "2                         0.471154                              0.5   \n",
       "3                         0.471154                              0.5   \n",
       "4                         0.471154                              0.5   \n",
       "\n",
       "   outgoing_textual_similarity  incoming_textual_similarity  is_name_in_mail  \\\n",
       "0                         -1.0                         -1.0              1.0   \n",
       "1                         -1.0                         -1.0             -1.0   \n",
       "2                         -1.0                         -1.0              1.0   \n",
       "3                         -1.0                         -1.0             -1.0   \n",
       "4                         -1.0                         -1.0             -1.0   \n",
       "\n",
       "   is_name_in_mail_short_                   recipient     mid  \\\n",
       "0                    -1.0    karen.herrmann@enron.com  298389   \n",
       "1                    -1.0  jennifer.mcquade@enron.com  298389   \n",
       "2                     1.0       john.hudson@enron.com  298389   \n",
       "3                    -1.0    reginald.smith@enron.com  298389   \n",
       "4                    -1.0            malley@enron.com  298389   \n",
       "\n",
       "                    sender  \n",
       "0  karen.buckley@enron.com  \n",
       "1  karen.buckley@enron.com  \n",
       "2  karen.buckley@enron.com  \n",
       "3  karen.buckley@enron.com  \n",
       "4  karen.buckley@enron.com  "
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df_w_features.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Features matrix creation for training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_negative(recipient_list, sender):\n",
    "    recipient_set = set(recipient_list)\n",
    "    candidates_negative = handbook_train[sender].difference(recipient_set)\n",
    "    return random.sample(candidates_negative, min(len(recipient_set), len(candidates_negative)))\n",
    "\n",
    "def create_data_train(row, sender):\n",
    "    out = []\n",
    "    recipient_list = row.recipients_valid\n",
    "    negative_recipients_list = generate_negative(recipient_list, sender)\n",
    "    for idx, recipient in enumerate(recipient_list):\n",
    "        # Positive\n",
    "        outgoing_message_percentage_ = outgoing_message_percentage(u=sender, c=recipient, t=row.date)\n",
    "        incoming_message_percentage_ = incoming_message_percentage(u=sender, c=recipient, t=row.date)\n",
    "        more_recent_outgoing_percentage_ = more_recent_outgoing_percentage(u=sender, c=recipient, t=row.date)\n",
    "        more_recent_incoming_percentage_ = more_recent_incoming_percentage(u=sender, c=recipient, t=row.date)\n",
    "        outgoing_textual_similarity_ = outgoing_textual_similarity_train(c=recipient, mid=row.mid) \n",
    "        incoming_textual_similarity_ = incoming_textual_similarity_train(c=recipient, mid=row.mid) \n",
    "        is_name_in_mail_short_ = is_name_in_mail_short(row.body_normalized, get_names(recipient))\n",
    "        \n",
    "        result = 1\n",
    "        \n",
    "        out.append([\n",
    "            outgoing_message_percentage_,\n",
    "            incoming_message_percentage_,\n",
    "            more_recent_outgoing_percentage_,\n",
    "            more_recent_incoming_percentage_,\n",
    "            outgoing_textual_similarity_,\n",
    "            incoming_textual_similarity_,\n",
    "            is_name_in_mail_short_,\n",
    "            recipient,\n",
    "            row.mid,\n",
    "            sender,\n",
    "            result\n",
    "        ])\n",
    "        if idx < len(negative_recipients_list):\n",
    "            # Negative\n",
    "            recipient = negative_recipients_list[idx]\n",
    "            outgoing_message_percentage_ = outgoing_message_percentage(u=sender, c=recipient, t=row.date)\n",
    "            incoming_message_percentage_ = incoming_message_percentage(u=sender, c=recipient, t=row.date)\n",
    "            more_recent_outgoing_percentage_ = more_recent_outgoing_percentage(u=sender, c=recipient, t=row.date)\n",
    "            more_recent_incoming_percentage_ = more_recent_incoming_percentage(u=sender, c=recipient, t=row.date)\n",
    "            outgoing_textual_similarity_ = outgoing_textual_similarity_train(c=recipient, mid=row.mid) \n",
    "            incoming_textual_similarity_ = incoming_textual_similarity_train(c=recipient, mid=row.mid) \n",
    "            is_name_in_mail_short_ = is_name_in_mail_short(row.body_normalized, get_names(recipient))\n",
    "            \n",
    "            result = -1\n",
    "\n",
    "            out.append([\n",
    "                outgoing_message_percentage_,\n",
    "                incoming_message_percentage_,\n",
    "                more_recent_outgoing_percentage_,\n",
    "                more_recent_incoming_percentage_,\n",
    "                outgoing_textual_similarity_,\n",
    "                incoming_textual_similarity_,\n",
    "                is_name_in_mail_short_,\n",
    "                recipient,\n",
    "                row.mid,\n",
    "                sender,\n",
    "                result\n",
    "            ])\n",
    "            \n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 - On considère: karen.buckley@enron.com\n",
      "On considère: karen.buckley@enron.com\n",
      "100.00% ----- Temps restant estimé: 0 min 0 sec -----\n",
      "1 - On considère: karen.buckley@enron.com\n",
      "On considère: amr.ibrahim@enron.com\n",
      "100.00% ----- Temps restant estimé: 0 min 0 sec -----\n",
      "2 - On considère: amr.ibrahim@enron.com\n",
      "On considère: andrea.ring@enron.com\n",
      "100.00% ----- Temps restant estimé: 0 min 0 sec -----\n",
      "3 - On considère: andrea.ring@enron.com\n",
      "On considère: sylvia.hu@enron.com\n",
      "100.00% ----- Temps restant estimé: 0 min 0 sec -----\n",
      "4 - On considère: sylvia.hu@enron.com\n",
      "On considère: phillip.platter@enron.com\n",
      "100.00% ----- Temps restant estimé: 0 min 0 sec -----\n",
      "5 - On considère: phillip.platter@enron.com\n",
      "On considère: richard.shapiro@enron.com\n",
      "100.00% ----- Temps restant estimé: 0 min 0 sec -----\n",
      "6 - On considère: richard.shapiro@enron.com\n",
      "On considère: megan.parker@enron.com\n",
      "100.00% ----- Temps restant estimé: 0 min 0 sec -----\n",
      "7 - On considère: megan.parker@enron.com\n",
      "On considère: david.forster@enron.com\n",
      "100.00% ----- Temps restant estimé: 0 min 0 sec -----\n",
      "8 - On considère: david.forster@enron.com\n",
      "On considère: mike.maggi@enron.com\n",
      "100.00% ----- Temps restant estimé: 0 min 0 sec -----\n",
      "9 - On considère: mike.maggi@enron.com\n",
      "On considère: justin.rostant@enron.com\n",
      "100.00% ----- Temps restant estimé: 0 min 0 sec -----\n",
      "10 - On considère: justin.rostant@enron.com\n",
      "On considère: marcus.nettelton@enron.com\n",
      "100.00% ----- Temps restant estimé: 0 min 0 sec -----\n",
      "11 - On considère: marcus.nettelton@enron.com\n",
      "On considère: kathleen.carnahan@enron.com\n",
      "100.00% ----- Temps restant estimé: 0 min 0 sec -----\n",
      "12 - On considère: kathleen.carnahan@enron.com\n",
      "On considère: grace.rodriguez@enron.com\n",
      "100.00% ----- Temps restant estimé: 0 min 0 sec -----\n",
      "13 - On considère: grace.rodriguez@enron.com\n",
      "On considère: hunter.s.shively@enron.com\n",
      "100.00% ----- Temps restant estimé: 0 min 0 sec -----\n",
      "14 - On considère: hunter.s.shively@enron.com\n",
      "On considère: sandra.f.brawner@enron.com\n",
      "100.00% ----- Temps restant estimé: 0 min 0 sec -----\n",
      "15 - On considère: sandra.f.brawner@enron.com\n",
      "On considère: l..nicolay@enron.com\n",
      "100.00% ----- Temps restant estimé: 0 min 0 sec -----\n",
      "16 - On considère: l..nicolay@enron.com\n",
      "On considère: mark.whitt@enron.com\n",
      "100.00% ----- Temps restant estimé: 0 min 0 sec -----\n",
      "17 - On considère: mark.whitt@enron.com\n",
      "On considère: james.derrick@enron.com\n",
      "100.00% ----- Temps restant estimé: 0 min 0 sec -----\n",
      "18 - On considère: james.derrick@enron.com\n",
      "On considère: darrell.schoolcraft@enron.com\n",
      "100.00% ----- Temps restant estimé: 0 min 0 sec -----\n",
      "19 - On considère: darrell.schoolcraft@enron.com\n",
      "On considère: l..denton@enron.com\n",
      "100.00% ----- Temps restant estimé: 0 min 0 sec -----\n",
      "20 - On considère: l..denton@enron.com\n",
      "On considère: cheryl.johnson@enron.com\n",
      "100.00% ----- Temps restant estimé: 0 min 0 sec -----\n",
      "21 - On considère: cheryl.johnson@enron.com\n",
      "On considère: scott.neal@enron.com\n",
      "100.00% ----- Temps restant estimé: 0 min 0 sec -----\n",
      "22 - On considère: scott.neal@enron.com\n",
      "On considère: chris.germany@enron.com\n",
      "100.00% ----- Temps restant estimé: 0 min 0 sec -----\n",
      "23 - On considère: chris.germany@enron.com\n",
      "On considère: eric.bass@enron.com\n",
      "100.00% ----- Temps restant estimé: 0 min 0 sec -----\n",
      "24 - On considère: eric.bass@enron.com\n",
      "On considère: larry.f.campbell@enron.com\n",
      "100.00% ----- Temps restant estimé: 0 min 0 sec -----\n",
      "25 - On considère: larry.f.campbell@enron.com\n",
      "On considère: lynn.blair@enron.com\n",
      "100.00% ----- Temps restant estimé: 0 min 0 sec -----\n",
      "26 - On considère: lynn.blair@enron.com\n",
      "On considère: nancy.sellers@robertmondavi.com\n",
      "100.00% ----- Temps restant estimé: 0 min 0 sec -----\n",
      "27 - On considère: nancy.sellers@robertmondavi.com\n",
      "On considère: harry.kingerski@enron.com\n",
      "100.00% ----- Temps restant estimé: 0 min 0 sec -----\n",
      "28 - On considère: harry.kingerski@enron.com\n",
      "On considère: m..forney@enron.com\n",
      "100.00% ----- Temps restant estimé: 0 min 0 sec -----\n",
      "29 - On considère: m..forney@enron.com\n",
      "On considère: stacey.w.white@enron.com\n",
      "100.00% ----- Temps restant estimé: 0 min 0 sec -----\n",
      "30 - On considère: stacey.w.white@enron.com\n",
      "On considère: rick.buy@enron.com\n",
      "100.00% ----- Temps restant estimé: 0 min 0 sec -----\n",
      "31 - On considère: rick.buy@enron.com\n",
      "On considère: matt.smith@enron.com\n",
      "100.00% ----- Temps restant estimé: 0 min 0 sec -----\n",
      "32 - On considère: matt.smith@enron.com\n",
      "On considère: dutch.quigley@enron.com\n",
      "100.00% ----- Temps restant estimé: 0 min 0 sec -----\n",
      "33 - On considère: dutch.quigley@enron.com\n",
      "On considère: greg.piper@enron.com\n",
      "100.00% ----- Temps restant estimé: 0 min 0 sec -----\n",
      "34 - On considère: greg.piper@enron.com\n",
      "On considère: stanley.horton@enron.com\n",
      "100.00% ----- Temps restant estimé: 0 min 0 sec -----\n",
      "35 - On considère: stanley.horton@enron.com\n",
      "On considère: liz.taylor@enron.com\n",
      "100.00% ----- Temps restant estimé: 0 min 0 sec -----\n",
      "36 - On considère: liz.taylor@enron.com\n",
      "On considère: jason.williams@enron.com\n",
      "100.00% ----- Temps restant estimé: 0 min 0 sec -----\n",
      "37 - On considère: jason.williams@enron.com\n",
      "On considère: taylor@enron.com\n",
      "100.00% ----- Temps restant estimé: 0 min 0 sec -----\n",
      "38 - On considère: taylor@enron.com\n",
      "On considère: alex@pira.com\n",
      "100.00% ----- Temps restant estimé: 0 min 0 sec -----\n",
      "39 - On considère: alex@pira.com\n",
      "On considère: mary.cook@enron.com\n",
      "100.00% ----- Temps restant estimé: 0 min 0 sec -----\n",
      "40 - On considère: mary.cook@enron.com\n",
      "On considère: m..schmidt@enron.com\n",
      "100.00% ----- Temps restant estimé: 0 min 0 sec -----\n",
      "41 - On considère: m..schmidt@enron.com\n",
      "On considère: joe.stepenovitch@enron.com\n",
      "100.00% ----- Temps restant estimé: 0 min 0 sec -----\n",
      "42 - On considère: joe.stepenovitch@enron.com\n",
      "On considère: mike.carson@enron.com\n",
      "100.00% ----- Temps restant estimé: 0 min 0 sec -----\n",
      "43 - On considère: mike.carson@enron.com\n",
      "On considère: paul.kaufman@enron.com\n",
      "100.00% ----- Temps restant estimé: 0 min 0 sec -----\n",
      "44 - On considère: paul.kaufman@enron.com\n",
      "On considère: sheila.glover@enron.com\n",
      "100.00% ----- Temps restant estimé: 0 min 0 sec -----\n",
      "45 - On considère: sheila.glover@enron.com\n",
      "On considère: jane.tholt@enron.com\n",
      "100.00% ----- Temps restant estimé: 0 min 0 sec -----\n",
      "46 - On considère: jane.tholt@enron.com\n",
      "On considère: monika.causholli@enron.com\n",
      "100.00% ----- Temps restant estimé: 0 min 0 sec -----\n",
      "47 - On considère: monika.causholli@enron.com\n",
      "On considère: jim.schwieger@enron.com\n",
      "100.00% ----- Temps restant estimé: 0 min 0 sec -----\n",
      "48 - On considère: jim.schwieger@enron.com\n",
      "On considère: andy.zipper@enron.com\n",
      "100.00% ----- Temps restant estimé: 0 min 0 sec -----\n",
      "49 - On considère: andy.zipper@enron.com\n",
      "On considère: janel.guerrero@enron.com\n",
      "100.00% ----- Temps restant estimé: 0 min 0 sec -----\n",
      "50 - On considère: janel.guerrero@enron.com\n",
      "On considère: kim.ward@enron.com\n",
      "100.00% ----- Temps restant estimé: 0 min 0 sec -----\n",
      "51 - On considère: kim.ward@enron.com\n",
      "On considère: lisa.mellencamp@enron.com\n",
      "100.00% ----- Temps restant estimé: 0 min 0 sec -----\n",
      "52 - On considère: lisa.mellencamp@enron.com\n",
      "On considère: beth.cherry@enform.com\n",
      "100.00% ----- Temps restant estimé: 0 min 0 sec -----\n",
      "53 - On considère: beth.cherry@enform.com\n",
      "On considère: david.port@enron.com\n",
      "100.00% ----- Temps restant estimé: 0 min 0 sec -----\n",
      "54 - On considère: david.port@enron.com\n",
      "On considère: kevin.m.presto@enron.com\n",
      "100.00% ----- Temps restant estimé: 0 min 0 sec -----\n",
      "55 - On considère: kevin.m.presto@enron.com\n",
      "On considère: mike.grigsby@enron.com\n",
      "100.00% ----- Temps restant estimé: 0 min 0 sec -----\n",
      "56 - On considère: mike.grigsby@enron.com\n",
      "On considère: julie.armstrong@enron.com\n",
      "100.00% ----- Temps restant estimé: 0 min 0 sec -----\n",
      "57 - On considère: julie.armstrong@enron.com\n",
      "On considère: wsmith@wordsmith.org\n",
      "100.00% ----- Temps restant estimé: 0 min 0 sec -----\n",
      "58 - On considère: wsmith@wordsmith.org\n",
      "On considère: martin.cuilla@enron.com\n",
      "100.00% ----- Temps restant estimé: 0 min 0 sec -----\n",
      "59 - On considère: martin.cuilla@enron.com\n",
      "On considère: phillip.m.love@enron.com\n",
      "100.00% ----- Temps restant estimé: 0 min 0 sec -----\n",
      "60 - On considère: phillip.m.love@enron.com\n",
      "On considère: rahil.jafry@enron.com\n",
      "100.00% ----- Temps restant estimé: 0 min 0 sec -----\n",
      "61 - On considère: rahil.jafry@enron.com\n",
      "On considère: tori.kuykendall@enron.com\n",
      "100.00% ----- Temps restant estimé: 0 min 0 sec -----\n",
      "62 - On considère: tori.kuykendall@enron.com\n",
      "On considère: kimberly.hillis@enron.com\n",
      "100.00% ----- Temps restant estimé: 0 min 0 sec -----\n",
      "63 - On considère: kimberly.hillis@enron.com\n",
      "On considère: bob.shults@enron.com\n",
      "100.00% ----- Temps restant estimé: 0 min 0 sec -----\n",
      "64 - On considère: bob.shults@enron.com\n",
      "On considère: michelle.cash@enron.com\n",
      "100.00% ----- Temps restant estimé: 0 min 0 sec -----\n",
      "65 - On considère: michelle.cash@enron.com\n",
      "On considère: vkaminski@aol.com\n",
      "100.00% ----- Temps restant estimé: 0 min 0 sec -----\n",
      "66 - On considère: vkaminski@aol.com\n",
      "On considère: james.d.steffes@enron.com\n",
      "100.00% ----- Temps restant estimé: 0 min 0 sec -----\n",
      "67 - On considère: james.d.steffes@enron.com\n",
      "On considère: marie.heard@enron.com\n",
      "100.00% ----- Temps restant estimé: 0 min 0 sec -----\n",
      "68 - On considère: marie.heard@enron.com\n",
      "On considère: jean.mrha@enron.com\n",
      "100.00% ----- Temps restant estimé: 0 min 0 sec -----\n",
      "69 - On considère: jean.mrha@enron.com\n",
      "On considère: patrice.l.mims@enron.com\n",
      "100.00% ----- Temps restant estimé: 0 min 0 sec -----\n",
      "70 - On considère: patrice.l.mims@enron.com\n",
      "On considère: peter.keohane@enron.com\n",
      "100.00% ----- Temps restant estimé: 0 min 0 sec -----\n",
      "71 - On considère: peter.keohane@enron.com\n",
      "On considère: andrew.edison@enron.com\n",
      "100.00% ----- Temps restant estimé: 0 min 0 sec -----\n",
      "72 - On considère: andrew.edison@enron.com\n",
      "On considère: suzanne.adams@enron.com\n",
      "100.00% ----- Temps restant estimé: 0 min 0 sec -----\n",
      "73 - On considère: suzanne.adams@enron.com\n",
      "On considère: shona.wilson@enron.com\n",
      "100.00% ----- Temps restant estimé: 0 min 0 sec -----\n",
      "74 - On considère: shona.wilson@enron.com\n",
      "On considère: schwabalerts.marketupdates@schwab.com\n",
      "100.00% ----- Temps restant estimé: 0 min 0 sec -----\n",
      "75 - On considère: schwabalerts.marketupdates@schwab.com\n",
      "On considère: holden.salisbury@enron.com\n",
      "100.00% ----- Temps restant estimé: 0 min 0 sec -----\n",
      "76 - On considère: holden.salisbury@enron.com\n",
      "On considère: w..cantrell@enron.com\n",
      "100.00% ----- Temps restant estimé: 0 min 0 sec -----\n",
      "77 - On considère: w..cantrell@enron.com\n",
      "On considère: john.zufferli@enron.com\n",
      "100.00% ----- Temps restant estimé: 0 min 0 sec -----\n",
      "78 - On considère: john.zufferli@enron.com\n",
      "On considère: alan.aronowitz@enron.com\n",
      "100.00% ----- Temps restant estimé: 0 min 0 sec -----\n",
      "79 - On considère: alan.aronowitz@enron.com\n",
      "On considère: barbo@enron.com\n",
      "100.00% ----- Temps restant estimé: 0 min 0 sec -----\n",
      "80 - On considère: barbo@enron.com\n",
      "On considère: brad.mckay@enron.com\n",
      "100.00% ----- Temps restant estimé: 0 min 0 sec -----\n",
      "81 - On considère: brad.mckay@enron.com\n",
      "On considère: stephanie.miller@enron.com\n",
      "100.00% ----- Temps restant estimé: 0 min 0 sec -----\n",
      "82 - On considère: stephanie.miller@enron.com\n",
      "On considère: jbennett@gmssr.com\n",
      "100.00% ----- Temps restant estimé: 0 min 0 sec -----\n",
      "83 - On considère: jbennett@gmssr.com\n",
      "On considère: sara.shackleton@enron.com\n",
      "100.00% ----- Temps restant estimé: 0 min 0 sec -----\n",
      "84 - On considère: sara.shackleton@enron.com\n",
      "On considère: lorna.brennan@enron.com\n",
      "100.00% ----- Temps restant estimé: 0 min 0 sec -----\n",
      "85 - On considère: lorna.brennan@enron.com\n",
      "On considère: mark.mcconnell@enron.com\n",
      "100.00% ----- Temps restant estimé: 0 min 0 sec -----\n",
      "86 - On considère: mark.mcconnell@enron.com\n",
      "On considère: susan.scott@enron.com\n",
      "100.00% ----- Temps restant estimé: 0 min 0 sec -----\n",
      "87 - On considère: susan.scott@enron.com\n",
      "On considère: stephanie.panus@enron.com\n",
      "100.00% ----- Temps restant estimé: 0 min 0 sec -----\n",
      "88 - On considère: stephanie.panus@enron.com\n",
      "On considère: karen.denne@enron.com\n",
      "100.00% ----- Temps restant estimé: 0 min 0 sec -----\n",
      "89 - On considère: karen.denne@enron.com\n",
      "On considère: mark.palmer@enron.com\n",
      "100.00% ----- Temps restant estimé: 0 min 0 sec -----\n",
      "90 - On considère: mark.palmer@enron.com\n",
      "On considère: jonathan.mckay@enron.com\n",
      "100.00% ----- Temps restant estimé: 0 min 0 sec -----\n",
      "91 - On considère: jonathan.mckay@enron.com\n",
      "On considère: becky.spencer@enron.com\n",
      "100.00% ----- Temps restant estimé: 0 min 0 sec -----\n",
      "92 - On considère: becky.spencer@enron.com\n",
      "On considère: joannie.williamson@enron.com\n",
      "100.00% ----- Temps restant estimé: 0 min 0 sec -----\n",
      "93 - On considère: joannie.williamson@enron.com\n",
      "On considère: alan.comnes@enron.com\n",
      "100.00% ----- Temps restant estimé: 0 min 0 sec -----\n",
      "94 - On considère: alan.comnes@enron.com\n",
      "On considère: paul.d.thomas@enron.com\n",
      "100.00% ----- Temps restant estimé: 0 min 0 sec -----\n",
      "95 - On considère: paul.d.thomas@enron.com\n",
      "On considère: chris.dorland@enron.com\n",
      "100.00% ----- Temps restant estimé: 0 min 0 sec -----\n",
      "96 - On considère: chris.dorland@enron.com\n",
      "On considère: ginger.dernehl@enron.com\n",
      "100.00% ----- Temps restant estimé: 0 min 0 sec -----\n",
      "97 - On considère: ginger.dernehl@enron.com\n",
      "On considère: cindy.stark@enron.com\n",
      "100.00% ----- Temps restant estimé: 0 min 0 sec -----\n",
      "98 - On considère: cindy.stark@enron.com\n",
      "On considère: david.portz@enron.com\n",
      "100.00% ----- Temps restant estimé: 0 min 0 sec -----\n",
      "99 - On considère: david.portz@enron.com\n",
      "On considère: tanya.rohauer@enron.com\n",
      "100.00% ----- Temps restant estimé: 0 min 0 sec -----\n",
      "100 - On considère: tanya.rohauer@enron.com\n",
      "On considère: stephanie.sever@enron.com\n",
      "100.00% ----- Temps restant estimé: 0 min 0 sec -----\n",
      "101 - On considère: stephanie.sever@enron.com\n",
      "On considère: sally.beck@enron.com\n",
      "100.00% ----- Temps restant estimé: 0 min 0 sec -----\n",
      "102 - On considère: sally.beck@enron.com\n",
      "On considère: keegan.farrell@enron.com\n",
      "100.00% ----- Temps restant estimé: 0 min 0 sec -----\n",
      "103 - On considère: keegan.farrell@enron.com\n",
      "On considère: kenneth.thibodeaux@enron.com\n",
      "100.00% ----- Temps restant estimé: 0 min 0 sec -----\n",
      "104 - On considère: kenneth.thibodeaux@enron.com\n",
      "On considère: christian.yoder@enron.com\n",
      "100.00% ----- Temps restant estimé: 0 min 0 sec -----\n",
      "105 - On considère: christian.yoder@enron.com\n",
      "On considère: brian.redmond@enron.com\n",
      "100.00% ----- Temps restant estimé: 0 min 0 sec -----\n",
      "106 - On considère: brian.redmond@enron.com\n",
      "On considère: russell.diamond@enron.com\n",
      "100.00% ----- Temps restant estimé: 0 min 0 sec -----\n",
      "107 - On considère: russell.diamond@enron.com\n",
      "On considère: john.lavorato@enron.com\n",
      "100.00% ----- Temps restant estimé: 0 min 0 sec -----\n",
      "108 - On considère: john.lavorato@enron.com\n",
      "On considère: ben.jacoby@enron.com\n",
      "100.00% ----- Temps restant estimé: 0 min 0 sec -----\n",
      "109 - On considère: ben.jacoby@enron.com\n",
      "On considère: britt.davis@enron.com\n",
      "100.00% ----- Temps restant estimé: 0 min 0 sec -----\n",
      "110 - On considère: britt.davis@enron.com\n",
      "On considère: holly.keiser@enron.com\n",
      "100.00% ----- Temps restant estimé: 0 min 0 sec -----\n",
      "111 - On considère: holly.keiser@enron.com\n",
      "On considère: michael.tribolet@enron.com\n",
      "100.00% ----- Temps restant estimé: 0 min 0 sec -----\n",
      "112 - On considère: michael.tribolet@enron.com\n",
      "On considère: errol.mclaughlin@enron.com\n",
      "100.00% ----- Temps restant estimé: 0 min 0 sec -----\n",
      "113 - On considère: errol.mclaughlin@enron.com\n",
      "On considère: heather.dunton@enron.com\n",
      "100.00% ----- Temps restant estimé: 0 min 0 sec -----\n",
      "114 - On considère: heather.dunton@enron.com\n",
      "On considère: christina.valdez@enron.com\n",
      "100.00% ----- Temps restant estimé: 0 min 0 sec -----\n",
      "115 - On considère: christina.valdez@enron.com\n",
      "On considère: jennifer.thome@enron.com\n",
      "100.00% ----- Temps restant estimé: 0 min 0 sec -----\n",
      "116 - On considère: jennifer.thome@enron.com\n",
      "On considère: jason.wolfe@enron.com\n",
      "100.00% ----- Temps restant estimé: 0 min 0 sec -----\n",
      "117 - On considère: jason.wolfe@enron.com\n",
      "On considère: tim.belden@enron.com\n",
      "100.00% ----- Temps restant estimé: 0 min 0 sec -----\n",
      "118 - On considère: tim.belden@enron.com\n",
      "On considère: mark.greenberg@enron.com\n",
      "100.00% ----- Temps restant estimé: 0 min 0 sec -----\n",
      "119 - On considère: mark.greenberg@enron.com\n",
      "On considère: fletcher.j.sturm@enron.com\n",
      "100.00% ----- Temps restant estimé: 0 min 0 sec -----\n",
      "120 - On considère: fletcher.j.sturm@enron.com\n",
      "On considère: c..giron@enron.com\n",
      "100.00% ----- Temps restant estimé: 0 min 0 sec -----\n",
      "121 - On considère: c..giron@enron.com\n",
      "On considère: barry.tycholiz@enron.com\n",
      "100.00% ----- Temps restant estimé: 0 min 0 sec -----\n",
      "122 - On considère: barry.tycholiz@enron.com\n",
      "On considère: amy.fitzpatrick@enron.com\n",
      "100.00% ----- Temps restant estimé: 0 min 0 sec -----\n",
      "123 - On considère: amy.fitzpatrick@enron.com\n",
      "On considère: c..williams@enron.com\n",
      "100.00% ----- Temps restant estimé: 0 min 0 sec -----\n",
      "124 - On considère: c..williams@enron.com\n",
      "On considère: enron_update@concureworkplace.com\n",
      "100.00% ----- Temps restant estimé: 0 min 0 sec -----\n"
     ]
    }
   ],
   "source": [
    "train_df_w_features = pd.DataFrame([], columns=['outgoing_message_percentage', 'incoming_message_percentage', 'more_recent_outgoing_percentage', 'more_recent_incoming_percentage', 'outgoing_textual_similarity', 'incoming_textual_similarity', 'is_name_in_mail', 'recipient', 'mid', 'sender', 'result'])\n",
    "for idx_sender in range(training.shape[0]):\n",
    "    print(\"%d - On considère: %s\" %(idx_sender, sender))\n",
    "    sender = training.sender[idx_sender]\n",
    "    print(\"On considère: %s\" %sender)\n",
    "    mids_sent = get_messages_written_by_u_to_c(u=sender, set_=training, set_info=training_info)\n",
    "    res = []\n",
    "    start_time = time()\n",
    "    finish_cursor = training_info[training_info.mid.isin(mids_sent)].shape[0]\n",
    "    for idx, row in enumerate(training_info[training_info.mid.isin(mids_sent)].iterrows()):\n",
    "        res += create_data_train(row[1], sender)\n",
    "        log_process(cursor=idx, finish_cursor=finish_cursor, start_time=start_time)\n",
    "    train_df_w_features = pd.concat((train_df_w_features, pd.DataFrame(res, columns=['outgoing_message_percentage', 'incoming_message_percentage', 'more_recent_outgoing_percentage', 'more_recent_incoming_percentage', 'outgoing_textual_similarity', 'incoming_textual_similarity', 'is_name_in_mail', 'recipient', 'mid', 'sender', 'result']))) \n",
    "    train_df_w_features.to_csv('train_df_w_features_FINAL', sep='\\t')\n",
    "    print"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Features matrix creation for test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_data_test(row, sender):\n",
    "    out = []\n",
    "    for recipient in handbook_train[sender]:\n",
    "        outgoing_message_percentage_ = outgoing_message_percentage(u=sender, c=recipient, t=row.date)\n",
    "        incoming_message_percentage_ = incoming_message_percentage(u=sender, c=recipient, t=row.date)\n",
    "        more_recent_outgoing_percentage_ = more_recent_outgoing_percentage(u=sender, c=recipient, t=row.date)\n",
    "        more_recent_incoming_percentage_ = more_recent_incoming_percentage(u=sender, c=recipient, t=row.date)\n",
    "        outgoing_textual_similarity_ = outgoing_textual_similarity(c=recipient, mid=row.mid) \n",
    "        incoming_textual_similarity_ = incoming_textual_similarity(c=recipient, mid=row.mid) \n",
    "        is_name_in_mail_ = is_name_in_mail_short(row.body_normalized, get_names(recipient))\n",
    "        \n",
    "        out.append([\n",
    "            outgoing_message_percentage_,\n",
    "            incoming_message_percentage_,\n",
    "            more_recent_outgoing_percentage_,\n",
    "            more_recent_incoming_percentage_,\n",
    "            outgoing_textual_similarity_,\n",
    "            incoming_textual_similarity_,\n",
    "            is_name_in_mail_,\n",
    "            recipient,\n",
    "            row.mid,\n",
    "            sender\n",
    "        ])\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_df_w_features = pd.DataFrame([], columns=['outgoing_message_percentage', 'incoming_message_percentage', 'more_recent_outgoing_percentage', 'more_recent_incoming_percentage', 'outgoing_message_percentage', 'incoming_message_percentage', 'more_recent_outgoing_percentage', 'more_recent_incoming_percentage', 'outgoing_textual_similarity', 'incoming_textual_similarity', 'is_name_in_mail', 'recipient', 'mid', 'sender'])\n",
    "for idx_sender in range(test.shape[0]):\n",
    "    sender = test.sender[idx_sender]\n",
    "    print(\"%d - On considère: %s\" %(idx_sender, sender))\n",
    "    mids_sent = get_messages_written_by_u_to_c(u=sender, set_=test, set_info=test_info)\n",
    "    res = []\n",
    "    start_time = time()\n",
    "    finish_cursor = test_info[test_info.mid.isin(mids_sent)].shape[0]\n",
    "    for idx, row in enumerate(test_info[test_info.mid.isin(mids_sent)].iterrows()):\n",
    "        res += create_data_test(row[1], sender)\n",
    "        log_process(cursor=idx, finish_cursor=finish_cursor, start_time=start_time)\n",
    "    test_df_w_features = pd.concat((test_df_w_features, pd.DataFrame(res, columns=['outgoing_message_percentage', 'incoming_message_percentage', 'more_recent_outgoing_percentage', 'more_recent_incoming_percentage', 'outgoing_message_percentage', 'incoming_message_percentage', 'more_recent_outgoing_percentage', 'more_recent_incoming_percentage', 'outgoing_textual_similarity', 'incoming_textual_similarity', 'is_name_in_mail', 'recipient', 'mid', 'sender']))) \n",
    "    test_df_w_features.to_csv('test_df_w_features_FINAL', sep='\\t')\n",
    "    print"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rf = MLPClassifier(hidden_layer_sizes=(100,), alpha=.0001)\n",
    "\n",
    "data_train = pd.get_dummies(train_df_w_features, columns=['sender'])\n",
    "data_test = pd.get_dummies(test_df_w_features, columns=['sender'])\n",
    "\n",
    "X = data_train.drop(['recipient', 'mid', 'result'], axis=1).values\n",
    "y = data_train[['result']].values.flatten()\n",
    "info = data_train[['recipient', 'mid', 'result']].values\n",
    "\n",
    "rf.fit(X, y)\n",
    "\n",
    "X_test = data_test.drop(['recipient', 'mid'], axis=1).values\n",
    "info_test = data_test[['recipient', 'mid']].values\n",
    "\n",
    "best_recipients = {}\n",
    "mids = set(map(int, info_test[:,1]))\n",
    "conc = np.concatenate((info_test, rf.predict_proba(X_test)[:,1,np.newaxis]), axis=1)\n",
    "conc_df = pd.DataFrame(conc, columns=['recipient', 'mid', 'proba'])\n",
    "for mid in mids:\n",
    "    best_recipients[mid] = conc_df[conc_df.mid==mid].sort_values('proba', ascending=False).recipient[:10].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "path_to_results = './'\n",
    "with open(path_to_results + 'predictions.txt', 'w') as my_file:\n",
    "    my_file.write('mid,recipients' + '\\n')\n",
    "    for mid, my_preds in best_recipients.items():\n",
    "        my_file.write(str(mid) + ',' + ' '.join(my_preds) + '\\n')"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
